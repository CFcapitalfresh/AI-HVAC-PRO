"""
SERVICE: SYNC SERVICE (FINAL SELF-CONTAINED FIX)
------------------------------------------------
1. Path Aware: Captures 'Brand | Model' properly.
2. Direct API Calls: Bypasses missing methods in DriveManager.
3. Update Only: Updates existing 'drive_index.json' to avoid Quota limits.
4. METADATA EXTRACTION: Extracts Brand, Model, and Meta_Type from file paths.
5. IMPROVEMENT: Scans ALL folders to build a complete index for browsing.
"""
import streamlit as st
import json
import os
from core.drive_manager import DriveManager
from core.config_loader import ConfigLoader
import logging
from googleapiclient.http import MediaIoBaseUpload
import io
import re
from services.sorter_logic import IGNORED_FOLDERS_TOP_LEVEL # Rule 3: Use shared ignored folders list

logger = logging.getLogger("Sync")
INDEX_FILENAME = "drive_index.json"

class SyncService:
    def __init__(self):
        self.drive = DriveManager()
        self.root_id = ConfigLoader.get_drive_folder_id()

    def scan_library(self):
        """Î£Î±ÏÏÎ½ÎµÎ¹ ÎºÎ±Î¹ Î•ÎÎ—ÎœÎ•Î¡Î©ÎÎ•Î™ (Update) Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ ÏƒÏ„Î¿ Cloud."""
        logger.info("ğŸ”„ Starting Sync (Direct Mode)...")
        
        if not self.root_id: 
            logger.error("âŒ Root ID missing.")
            return []
        
        # ÎœÏ€Î¬ÏÎ± Î ÏÎ¿ÏŒÎ´Î¿Ï…
        progress_text = "â³ Î£Î¬ÏÏ‰ÏƒÎ· & Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·..."
        my_bar = st.progress(0, text=progress_text)
        
        # 1. Î£Î‘Î¡Î©Î£Î— (Path Aware)
        # Call _scan_recursive to scan all files, without skipping any categorized folders
        # Rule 3: Pass force_full_rescan_for_sync to avoid scanning ignored folders during a regular sync,
        # but scan them if explicitly told to for a full re-index.
        all_files = self._scan_recursive(self.root_id, path_prefix="", my_bar=my_bar, progress_text=progress_text, current_progress=0, total_progress_steps=80, force_full_rescan_for_sync=True)
        
        my_bar.progress(80, text=f"âœ… Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(all_files)} Î±ÏÏ‡ÎµÎ¯Î±. Î•Î³Î³ÏÎ±Ï†Î® ÏƒÏ„Î¿ Cloud...")
        logger.info(f"âœ… Scan Complete. Found {len(all_files)} manuals.")

        # 2. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î¤Î¿Ï€Î¹ÎºÎ¬ (Backup)
        try:
            with open(INDEX_FILENAME, "w", encoding="utf-8") as f:
                json.dump(all_files, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ Local index saved: {INDEX_FILENAME}")
        except Exception as e:
            logger.warning(f"Failed to save local index: {e}", exc_info=True) # Rule 4

        # 3. CLOUD UPDATE (Direct API Call - Î§Ï‰ÏÎ¯Ï‚ Î¼ÎµÏƒÎ¬Î¶Î¿Î½Ï„ÎµÏ‚)
        try:
            # Î‘Ï€ÎµÏ…Î¸ÎµÎ¯Î±Ï‚ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î¼Î­ÏƒÏ‰ Ï„Î¿Ï… service (Ï€Î±ÏÎ±ÎºÎ¬Î¼Ï€Ï„Î¿Ï…Î¼Îµ Ï„Î¿ DriveManager)
            query = f"name = '{INDEX_FILENAME}' and '{self.root_id}' in parents and trashed = false"
            results = self.drive.service.files().list(q=query, fields="files(id, name)").execute()
            found_files = results.get('files', [])
            
            if not found_files:
                logger.error("âŒ CLOUD ERROR: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ 'drive_index.json'!")
                st.error("âš ï¸ Î£Ï†Î¬Î»Î¼Î±: Î ÏÎ­Ï€ÎµÎ¹ Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÎµÏ„Îµ Î­Î½Î± ÎºÎµÎ½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿ 'drive_index.json' ÏƒÏ„Î¿ Drive ÏƒÎ±Ï‚!")
                return all_files

            # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿ ID Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…
            target_file_id = found_files[0]['id']
            logger.info(f"ğŸ“‚ Found Cloud Index ID: {target_file_id}")
            
            # Î•Ï„Î¿Î¹Î¼Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
            json_str = json.dumps(all_files, ensure_ascii=False, indent=2)
            media = MediaIoBaseUpload(io.BytesIO(json_str.encode('utf-8')), mimetype='application/json', resumable=True)

            # Î•ÎšÎ¤Î•Î›Î•Î£Î— UPDATE
            self.drive.service.files().update(
                fileId=target_file_id,
                media_body=media
            ).execute()
            
            logger.info(f"â˜ï¸ Cloud Index OVERWRITTEN successfully!")
            my_bar.progress(100, text="âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î— Î²Î¬ÏƒÎ· ÎµÎ½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎµ.")
            
            # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Session
            if 'library_index' in st.session_state:
                del st.session_state['library_index']
            if 'library_cache' in st.session_state: # Clear cache from ui_search
                del st.session_state['library_cache']
                
            return all_files
            
        except Exception as e:
            logger.error(f"âŒ Cloud Update Failed: {e}", exc_info=True) # Rule 4
            st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· Cloud: {e}")
            return all_files

    def _extract_metadata_from_name(self, full_path_name: str, original_filename: str) -> dict:
        """
        Î•Î¾Î¬Î³ÎµÎ¹ Î¼ÎµÏ„Î±Î´ÎµÎ´Î¿Î¼Î­Î½Î± (category, brand, model, meta_type, error_codes) Î±Ï€ÏŒ Î­Î½Î± ÏŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…
        Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Î¼Î¿ÏÏ†Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ Î±Ï€ÏŒ Ï„Î¿Î½ Sorter (Ï€.Ï‡., "Category | Brand | Model | Type | Filename.pdf")
        Î® Î±Ï€ÏŒ Ï„Î·Î½ original_filename Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï€Î»Î®ÏÎ·Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î®.
        """
        metadata = {
            'category': 'Unknown', # NEW: Include category in metadata
            'brand': 'Unknown',
            'model': 'General_Model', # Changed from 'General Model' for consistency
            'meta_type': 'General_Manual', # Changed from 'DOC' for consistency with Sorter
            'error_codes': '', 
            'original_name': original_filename 
        }

        # Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± Î´Î¹Î±ÏƒÏ€Î¬ÏƒÎ¿Ï…Î¼Îµ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ '|' Î±Ï€ÏŒ Ï„Î·Î½ Ï€Î»Î®ÏÎ· Î´Î¹Î±Î´ÏÎ¿Î¼Î®
        parts = [p.strip() for p in full_path_name.split('|')]
        
        if len(parts) >= 5: # Assuming format "Category | Brand | Model | Type | Filename"
            metadata['category'] = parts[0].replace(" ", "_")
            metadata['brand'] = parts[1].replace(" ", "_")
            metadata['model'] = parts[2].replace(" ", "_")
            metadata['meta_type'] = parts[3].replace(" ", "_")
            # The last part is the original filename, but error codes might be embedded.
            # For now, error_codes is still extracted by AI, but we can look for common patterns.
        elif len(parts) >= 4: # Assuming format "Category | Brand | Model | Filename" (Type might be missing)
            metadata['category'] = parts[0].replace(" ", "_")
            metadata['brand'] = parts[1].replace(" ", "_")
            metadata['model'] = parts[2].replace(" ", "_")
            # meta_type defaults, or can be inferred from filename if simple.
        
        # Simple regex for error codes in original filename
        error_match = re.search(r'[E]{1}\d+', original_filename, re.IGNORECASE)
        if error_match:
            metadata['error_codes'] = error_match.group(0).upper()

        return metadata

    def _scan_recursive(self, folder_id, path_prefix="", my_bar=None, progress_text="", current_progress=0, total_progress_steps=100, force_full_rescan_for_sync: bool = False):
        """
        Î£Î±ÏÏÎ½ÎµÎ¹ Î±Î½Î±Î´ÏÎ¿Î¼Î¹ÎºÎ¬ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ ÏƒÏ„Î¿ Google Drive ÎºÎ±Î¹ ÏƒÏ…Î»Î»Î­Î³ÎµÎ¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½.
        Î•Î½Î·Î¼ÎµÏÏÎ½ÎµÎ¹ Ï„Î· Î¼Ï€Î¬ÏÎ± Ï€ÏÎ¿ÏŒÎ´Î¿Ï….
        Args:
            folder_id (str): Î¤Î¿ ID Ï„Î¿Ï… Ï†Î±ÎºÎ­Î»Î¿Ï… Î±Ï€ÏŒ ÏŒÏ€Î¿Ï… Î¸Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î· ÏƒÎ¬ÏÏ‰ÏƒÎ·.
            path_prefix (str): Î¤Î¿ prefix Ï„Î·Ï‚ Î´Î¹Î±Î´ÏÎ¿Î¼Î®Ï‚ Î³Î¹Î± Ï„Î·Î½ Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Î±Î½Î±Î´ÏÎ¿Î¼Î¹ÎºÎ® ÎºÎ»Î®ÏƒÎ·.
            my_bar (st.progress): Î— Î¼Ï€Î¬ÏÎ± Ï€ÏÎ¿ÏŒÎ´Î¿Ï… Ï„Î¿Ï… Streamlit.
            progress_text (str): Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï€Î¿Ï… Î¸Î± ÎµÎ¼Ï†Î±Î½Î¯Î¶ÎµÏ„Î±Î¹ ÏƒÏ„Î·Î½ Î¼Ï€Î¬ÏÎ± Ï€ÏÎ¿ÏŒÎ´Î¿Ï….
            current_progress (int): Î— Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Ï„Î¹Î¼Î® Ï€ÏÎ¿ÏŒÎ´Î¿Ï….
            total_progress_steps (int): Î¤Î¿ ÏƒÏ…Î½Î¿Î»Î¹ÎºÏŒ ÎµÏÏÎ¿Ï‚ Ï€ÏÎ¿ÏŒÎ´Î¿Ï… Î³Î¹Î± Î±Ï…Ï„Î® Ï„Î· ÏƒÎ¬ÏÏ‰ÏƒÎ·.
            force_full_rescan_for_sync (bool): Î‘Î½ ÎµÎ¯Î½Î±Î¹ True, ÏƒÎ±ÏÏÎ½ÎµÎ¹ ÎºÎ±Î¹ Ï„Î¿Ï…Ï‚ ÎµÎ¹Î´Î¹ÎºÎ¿ÏÏ‚ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ (Ï€.Ï‡., _IRRELEVANT_OR_UNKNOWN).
        Returns:
            List[Dict]: Î›Î¯ÏƒÏ„Î± Î¼Îµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½.
        """
        all_files_info = []
        q_param = f"'{folder_id}' in parents and trashed = false"

        try:
            # Î›Î¯ÏƒÏ„Î± Ï†Î±ÎºÎ­Î»Ï‰Î½ ÎºÎ±Î¹ Î±ÏÏ‡ÎµÎ¯Ï‰Î½
            response = self.drive.service.files().list(
                q=q_param, fields="files(id, name, mimeType, webViewLink, parents)"
            ).execute()
            items = response.get('files', [])

            # Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Ï…Î¼Îµ Î­Î½Î± Î²Î®Î¼Î± Ï€ÏÎ¿ÏŒÎ´Î¿Ï… Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ ÏƒÎµ Î±Ï…Ï„ÏŒ Ï„Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿
            # Î”ÎµÎ½ ÎµÎ½Î·Î¼ÎµÏÏÎ½Î¿Ï…Î¼Îµ Ï„Î· Î¼Ï€Î¬ÏÎ± ÎµÎ´Ï, Î±Ï†Î®Î½Î¿Ï…Î¼Îµ Ï„Î¿Î½ ÎºÎ±Î»Î¿ÏÎ½Ï„Î± Î½Î± Ï„Î¿ ÎºÎ¬Î½ÎµÎ¹
            
            for item in items:
                file_name = item['name']
                mime_type = item['mimeType']
                file_id = item['id']

                full_path_name = f"{path_prefix} | {file_name}" if path_prefix else file_name
                
                if mime_type == 'application/vnd.google-apps.folder':
                    # Rule 3: Do not scan ignored folders UNLESS force_full_rescan_for_sync is True (for a complete index)
                    if file_name.startswith('_') and file_name in IGNORED_FOLDERS_TOP_LEVEL and not force_full_rescan_for_sync:
                        logger.info(f"Skipping ignored folder: {full_path_name}")
                        continue
                    # Î‘Î½Î±Î´ÏÎ¿Î¼Î¹ÎºÎ® ÎºÎ»Î®ÏƒÎ· Î³Î¹Î± Ï…Ï€Î¿Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚
                    nested_files = self._scan_recursive(
                        file_id, full_path_name, my_bar, progress_text, 
                        current_progress, total_progress_steps, force_full_rescan_for_sync
                    )
                    all_files_info.extend(nested_files)
                elif mime_type == 'application/pdf':
                    # Î•Î¾Î±Î³Ï‰Î³Î® Î¼ÎµÏ„Î±Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
                    metadata = self._extract_metadata_from_name(full_path_name, file_name)
                    all_files_info.append({
                        'file_id': file_id,
                        'name': full_path_name, # The full path name created by sorter
                        'link': item.get('webViewLink'),
                        'mime': mime_type,
                        'category': metadata['category'], # NEW METADATA FIELD
                        'brand': metadata['brand'],
                        'model': metadata['model'],
                        'meta_type': metadata['meta_type'],
                        'error_codes': metadata['error_codes'],
                        'original_name': file_name # Keep the original filename
                    })
                    # Update progress bar (Rule 3)
                    if my_bar:
                        # Increment progress by a tiny amount for each file found
                        current_progress += 1 
                        my_bar.progress(min(current_progress, total_progress_steps), text=f"{progress_text} - Scanning: {file_name}")

            return all_files_info
        except Exception as e:
            logger.error(f"Error scanning folder {folder_id} with prefix '{path_prefix}': {e}", exc_info=True) # Rule 4
            return []

    def load_index(self) -> List[Dict[str, Any]]:
        """
        Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ 'drive_index.json' Î±Ï€ÏŒ Ï„Î¿Ï€Î¹ÎºÏŒ Î´Î¯ÏƒÎºÎ¿ Î® Ï„Î¿ Google Drive.
        Î•Ï€Î¯ÏƒÎ·Ï‚, cache-Î¬ÏÎµÎ¹ Ï„Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± ÏƒÏ„Î¿ session state.
        """
        if 'library_index' in st.session_state and st.session_state.library_index:
            logger.info("Serving library index from session cache.")
            return st.session_state.library_index

        logger.info("Loading library index...")
        index_data = []

        # 1. Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ Ï„Î¿Ï€Î¹ÎºÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
        if os.path.exists(INDEX_FILENAME):
            try:
                with open(INDEX_FILENAME, "r", encoding="utf-8") as f:
                    index_data = json.load(f)
                logger.info("Local index loaded successfully.")
                st.session_state.library_index = index_data
                return index_data
            except Exception as e:
                logger.warning(f"Failed to load local index file: {e}", exc_info=True) # Rule 4

        # 2. Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹, Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ Google Drive
        if self.root_id:
            try:
                query = f"name = '{INDEX_FILENAME}' and '{self.root_id}' in parents and trashed = false"
                results = self.drive.service.files().list(q=query, fields="files(id, name)").execute()
                found_files = results.get('files', [])

                if found_files:
                    file_id = found_files[0]['id']
                    file_content_stream = self.drive.download_file_content(file_id)
                    if file_content_stream:
                        index_data = json.load(file_content_stream)
                        logger.info("Cloud index loaded successfully.")
                        
                        # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎºÎ±Î¹ Ï„Î¿Ï€Î¹ÎºÎ¬ Î³Î¹Î± Î¼ÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ· (Rule 4)
                        with open(INDEX_FILENAME, "w", encoding="utf-8") as f:
                            json.dump(index_data, f, ensure_ascii=False, indent=2)
                        logger.info("Cloud index saved locally.")

                        st.session_state.library_index = index_data
                        return index_data
                    else:
                        logger.error(f"Failed to download content of '{INDEX_FILENAME}' from Drive.") # Rule 4
                else:
                    logger.warning(f"'{INDEX_FILENAME}' not found in Google Drive root folder.") # Rule 4
            except Exception as e:
                logger.error(f"Failed to load index from Google Drive: {e}", exc_info=True) # Rule 4
        else:
            logger.warning("Root Drive folder ID is not configured. Cannot load index from Drive.") # Rule 4

        logger.warning("No library index could be loaded. Returning empty list.")
        st.session_state.library_index = [] # Rule 6
        return []