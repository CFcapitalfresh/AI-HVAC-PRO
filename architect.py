import streamlit as st
import os
import shutil
import re
import time
import ast
from datetime import datetime
try:
    from groq import Groq
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    st.error("âš ï¸ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚. Î¤ÏÎ­Î¾Îµ: pip install groq streamlit-mic-recorder")
    st.stop()

# --- 1. Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ INTERFACE ---
st.set_page_config(page_title="Architect AI v41 (Mentor Mode)", page_icon="ğŸ—ï¸", layout="wide")

# --- 2. Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ•Î£ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î•Î™Î£ ---
def get_project_context():
    """Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï„Î¿Ï… project (ÏƒÏ…Î¼Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î±Î½Î¿Î¼Î­Î½Î¿Ï… Ï„Î¿Ï… architect.py)."""
    root_dir = os.path.dirname(os.path.abspath(__file__))
    file_contents = {}
    # Î‘Ï†Î±Î¹ÏÎ­ÏƒÎ±Î¼Îµ Ï„Î¿ .streamlit Î±Ï€ÏŒ Ï„Î¿ ignore Î±Î½ Î¸ÎµÏ‚ Î½Î± Î²Î»Î­Ï€ÎµÎ¹ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚, 
    # Î±Î»Î»Î¬ ÎºÏÎ±Ï„Î¬Î¼Îµ Ï„Î± backups ÎºÎ±Î¹ Ï„Î± venv ÎµÎºÏ„ÏŒÏ‚.
    ignore = {'.git', '__pycache__', 'venv', 'backups', '.DS_Store'} 
    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if d not in ignore]
        for f in filenames:
            # Î”Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ py, json, css, txt, md
            if f.endswith(('.py', '.json', '.css', '.txt', '.md')):
                try:
                    rel_path = os.path.relpath(os.path.join(dirpath, f), root_dir)
                    with open(os.path.join(dirpath, f), 'r', encoding='utf-8', errors='ignore') as file:
                        # Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î³Î¹Î± Î½Î± Î¼Î·Î½ ÏƒÎºÎ¬ÎµÎ¹ Ï„Î¿ ÏŒÏÎ¹Î¿ tokens (Rate Limit)
                        content = file.read()
                        if len(content) > 7000:
                            content = content[:3500] + "\n... [truncated] ...\n" + content[-3500:]
                        file_contents[rel_path] = content
                except: pass
    return file_contents

def apply_code_changes(response_text):
    """Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ Ï„Î¹Ï‚ Î±Î»Î»Î±Î³Î­Ï‚ Ï€Î¿Ï… Ï€ÏÎ¿Ï„ÎµÎ¯Î½ÎµÎ¹ Ï„Î¿ AI."""
    pattern = r"### FILE: (.+?)\n.*?```(?:python|json|css)?\n(.*?)```"
    matches = re.findall(pattern, response_text, re.DOTALL)
    log = []
    if not matches: return "â„¹ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÎºÏÎ´Î¹ÎºÎ±Ï‚ Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·."
    for filename, code in matches:
        filename = filename.strip().replace("\\", "/")
        full_path = os.path.abspath(filename)
        if os.path.exists(full_path):
            b_dir = os.path.join(os.path.dirname(full_path), "backups")
            os.makedirs(b_dir, exist_ok=True)
            shutil.copy2(full_path, os.path.join(b_dir, f"{os.path.basename(full_path)}_{datetime.now().strftime('%H%M%S')}.bak"))
        try:
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            with open(full_path, 'w', encoding='utf-8') as f: f.write(code.strip())
            log.append(f"âœ… UPDATED: {filename}")
        except Exception as e: log.append(f"âŒ ERROR: {filename} ({e})")
    return "\n".join(log)

# --- 3. Î— ÎœÎ—Î§Î‘ÎÎ— Î¤Î—Î£ META (GROQ) ---
def run_llama_logic(prompt_text, api_key):
    if not api_key: return "âŒ Î›ÎµÎ¯Ï€ÎµÎ¹ Ï„Î¿ Groq API Key."
    client = Groq(api_key=api_key)
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {
                    "role": "system", 
                    "content": "Î•Î¯ÏƒÎ±Î¹ Î¿ Mastro Nek, Senior AI Architect. ÎœÎ¯Î»Î± Ï€Î¬Î½Ï„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬. Î•Î¾Î®Î³Î·ÏƒÎµ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Ï„Î¿ Ï€Î»Î¬Î½Î¿ ÏƒÎ¿Ï… Ï€ÏÎ¹Î½ Î´ÏÏƒÎµÎ¹Ï‚ ÎºÏÎ´Î¹ÎºÎ±. ÎœÎ·Î½ Î´Î¯Î½ÎµÎ¹Ï‚ Î¼ÏŒÎ½Î¿ ÏƒÏÎ¼Î²Î¿Î»Î±."
                },
                {"role": "user", "content": prompt_text}
            ],
            temperature=0.3, # Î›Î¯Î³Î¿ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î± Î³Î¹Î± Ï„Î·Î½ ÎµÏ€ÎµÎ¾Î·Î³Î®ÏƒÎ·
            max_tokens=8192,
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"âŒ Groq Error: {str(e)}"

# --- 4. UI ---
def main():
    st.title("ğŸ—ï¸ Architect AI v41 (Mentor Mode)")
    
    with st.sidebar:
        st.header("Settings")
        api_key = st.text_input("Groq API Key", type="password")
        st.divider()
        audio = mic_recorder(start_prompt="ğŸ¤ Rec (Voice)", stop_prompt="â¹ Stop", key='mic_v41')
        st.divider()
        if st.button("ğŸ—‘ï¸ Clear Chat History"):
            st.session_state.messages = []
            st.rerun()
        
        strategy = st.selectbox("Strategy", ["Bug Fix", "New Feature", "Refactor", "Self-Upgrade"])
        auto_save = st.checkbox("Auto-Save", value=False)

    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    user_prompt = st.chat_input("Î ÏÏ‚ Î¼Ï€Î¿ÏÏ Î½Î± Î²Î¿Î·Î¸Î®ÏƒÏ‰ ÏƒÏ„Î¿ Project ÏƒÎ®Î¼ÎµÏÎ±;")
    
    if (user_prompt or audio) and api_key:
        input_msg = user_prompt if user_prompt else "Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ® ÎµÎ½Ï„Î¿Î»Î®..."
        st.session_state.messages.append({"role": "user", "content": input_msg})
        with st.chat_message("user"): st.markdown(input_msg)

        # Build Context
        project_data = get_project_context()
        context_str = "PROJECT FILES:\n" + "\n".join([f"--- {n} ---\n{c}" for n, c in project_data.items()])
        
        full_prompt = f"""
        Î¡ÎŸÎ›ÎŸÎ£: Senior Architect (Mastro Nek). 
        CONTEXT: HVAC SaaS Project.
        Î“Î›Î©Î£Î£Î‘: Î•Î›Î›Î—ÎÎ™ÎšÎ‘.
        
        ÎŸÎ”Î—Î“Î™Î•Î£:
        1. ÎÎµÎºÎ¯Î½Î± Î¼Îµ Î¼Î¹Î± ÏƒÏÎ½Ï„Î¿Î¼Î· Î±Î½Î¬Î»Ï…ÏƒÎ· ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬. Î•Î¾Î®Î³Î·ÏƒÎµ Ï„Î¹ Î¸Î± Î±Î»Î»Î¬Î¾ÎµÎ¹Ï‚.
        2. ÎœÎµÏ„Î¬ Ï„Î·Î½ ÎµÎ¾Î®Î³Î·ÏƒÎ·, Î´ÏÏƒÎµ Ï„Î¿Î½ Î Î›Î—Î¡Î— ÎºÏÎ´Î¹ÎºÎ±.
        3. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¿ format: ### FILE: filename.py \n ```python ... ```
        
        PROJECT DATA:
        {context_str}
        
        REQUEST: {input_msg}
        """

        with st.chat_message("assistant"):
            with st.spinner("ÎŸ Î‘ÏÏ‡Î¹Ï„Î­ÎºÏ„Î¿Î½Î±Ï‚ Î±Î½Î±Î»ÏÎµÎ¹..."):
                response = run_llama_logic(full_prompt, api_key)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                if "### FILE:" in response:
                    if auto_save or st.button("ğŸ’¾ Apply Changes"):
                        res_log = apply_code_changes(response)
                        st.code(res_log)
                        time.sleep(1)
                        st.rerun()

if __name__ == "__main__":
    main()