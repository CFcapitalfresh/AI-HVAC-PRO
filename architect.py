import streamlit as st
import os
import shutil
import ast
import re
import time
from datetime import datetime
import google.generativeai as genai
from streamlit_mic_recorder import mic_recorder

# --- 1. Î‘Î¡Î§Î™ÎšÎ•Î£ Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ---
st.set_page_config(page_title="Architect AI v35 (Universal)", page_icon="ğŸš€", layout="wide")

# --- 2. Î’ÎŸÎ—Î˜Î—Î¤Î™ÎšÎ•Î£ Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î•Î™Î£ Î£Î¥Î£Î¤Î—ÎœÎ‘Î¤ÎŸÎ£ ---
def get_project_context():
    """Î£Î±ÏÏÎ½ÎµÎ¹ Ï„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ Î³Î¹Î± Î½Î± Î´ÏÏƒÎµÎ¹ ÏƒÏ„Î¿ AI ÎµÎ¹ÎºÏŒÎ½Î± Î¿Î»ÏŒÎºÎ»Î·ÏÎ¿Ï… Ï„Î¿Ï… project."""
    root_dir = os.path.dirname(os.path.abspath(__file__))
    file_contents = {}
    ignore = {'.git', '__pycache__', 'venv', '.streamlit', 'backups', '.DS_Store', 'requirements.txt'} 
    
    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if d not in ignore]
        for f in filenames:
            if f in ignore or f.endswith(('.pyc', '.png', '.jpg', '.pdf', '.mp3', '.xlsx', '.bak')): continue 
            try:
                path = os.path.join(dirpath, f)
                rel_path = os.path.relpath(path, root_dir)
                with open(path, 'r', encoding='utf-8', errors='ignore') as file:
                    file_contents[rel_path] = file.read()
            except: pass
    return file_contents

def apply_code_changes(response_text):
    """Î•Î¾Î¬Î³ÎµÎ¹ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ± Î±Ï€ÏŒ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏÎ½ÎµÎ¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î±."""
    pattern = r"### FILE: (.+?)\n.*?```(?:python)?\n(.*?)```"
    matches = re.findall(pattern, response_text, re.DOTALL)
    log = []
    
    if not matches: return "â„¹ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÎºÏÎ´Î¹ÎºÎ±Ï‚ Ï€ÏÎ¿Ï‚ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·."

    for filename, code in matches:
        filename = filename.strip().replace("\\", "/")
        if filename.startswith("./"): filename = filename[2:]
        full_path = os.path.abspath(filename)
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Backup
        if os.path.exists(full_path):
            backup_dir = os.path.join(os.path.dirname(full_path), "backups")
            os.makedirs(backup_dir, exist_ok=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            shutil.copy2(full_path, os.path.join(backup_dir, f"{os.path.basename(full_path)}_{ts}.bak"))

        try:
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(code.strip())
            log.append(f"âœ… UPDATED: {filename}")
        except Exception as e:
            log.append(f"âŒ ERROR: {filename} ({str(e)})")
            
    return "\n".join(log)

# --- 3. Î— ÎœÎ—Î§Î‘ÎÎ— Î¤ÎŸÎ¥ AI (Dynamic Seeker) ---
def run_ai_logic(parts, api_key):
    if not api_key: return "âŒ Î£Ï†Î¬Î»Î¼Î±: Î›ÎµÎ¯Ï€ÎµÎ¹ Ï„Î¿ API Key."
    
    genai.configure(api_key=api_key)
    
    try:
        # Î”Ï…Î½Î±Î¼Î¹ÎºÎ® Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # Î•Ï€Î¹Î»Î¿Î³Î® Î¼Î¿Î½Ï„Î­Î»Î¿Ï… Î¼Îµ ÏƒÎµÎ¹ÏÎ¬ Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±Ï‚
        selected_model = None
        for target in ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"]:
            for m in models:
                if target in m:
                    selected_model = m
                    break
            if selected_model: break
            
        if not selected_model:
            return f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ…Î¼Î²Î±Ï„ÏŒ Î¼Î¿Î½Ï„Î­Î»Î¿. Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î±: {str(models)}"

        model = genai.GenerativeModel(selected_model)
        config = genai.types.GenerationConfig(temperature=0.2, max_output_tokens=8192)
        
        response = model.generate_content(parts, generation_config=config)
        return response.text
    except Exception as e:
        return f"âŒ AI ERROR: {str(e)}"

# --- 4. Î Î•Î¡Î™Î’Î‘Î›Î›ÎŸÎ Î§Î¡Î—Î£Î¤Î— (UI) ---
def main():
    st.title("ğŸš€ Architect AI v35 (Universal Seeker)")
    
    with st.sidebar:
        st.header("Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")
        api_key = st.text_input("Gemini API Key", type="password")
        if not api_key and "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("Î¤Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ!")

        st.divider()
        st.subheader("ğŸ¤ Î¦Ï‰Î½Î® & ğŸ“‚ Î‘ÏÏ‡ÎµÎ¯Î±")
        audio = mic_recorder(start_prompt="ğŸ¤ Rec", stop_prompt="â¹ Stop", key='mic_v35')
        uploaded = st.file_uploader("Screenshot Î® PDF", type=['png','jpg','pdf'], label_visibility="collapsed")
        
        st.divider()
        project_data = get_project_context()
        strategy = st.selectbox("Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®", ["ÎÎ­Î± Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±", "Î”Î¹ÏŒÏÎ¸Ï‰ÏƒÎ· Bug", "Î’ÎµÎ»Ï„Î¯Ï‰ÏƒÎ· ÎšÏÎ´Î¹ÎºÎ±"])
        focus_file = st.selectbox("Î‘ÏÏ‡ÎµÎ¯Î¿ Î•ÏƒÏ„Î¯Î±ÏƒÎ·Ï‚", ["ÎŸÎ»ÏŒÎºÎ»Î·ÏÎ¿ Ï„Î¿ Project"] + list(project_data.keys()))
        auto_save = st.checkbox("Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·", value=False)

    # Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î™ÏƒÏ„Î¿ÏÎ¹ÎºÎ¿Ï Chat
    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    # Î•Î¯ÏƒÎ¿Î´Î¿Ï‚ Î§ÏÎ®ÏƒÏ„Î·
    user_prompt = st.chat_input("Î ÏÏ‚ Î¼Ï€Î¿ÏÏ Î½Î± Î²Î¿Î·Î¸Î®ÏƒÏ‰ ÏƒÏ„Î¿ project ÏƒÎ®Î¼ÎµÏÎ±;")
    
    if (user_prompt or audio or uploaded) and api_key:
        input_msg = user_prompt if user_prompt else "Î‘Î½Î¬Î»Ï…ÏƒÎ· Î±ÏÏ‡ÎµÎ¯Î¿Ï…/Ï†Ï‰Î½Î®Ï‚..."
        st.session_state.messages.append({"role": "user", "content": input_msg})
        with st.chat_message("user"): st.markdown(input_msg)

        # ÎšÎ±Ï„Î±ÏƒÎºÎµÏ…Î® Context Î³Î¹Î± Ï„Î¿ AI
        context_summary = "PROJECT STRUCTURE:\n" + "\n".join([f"--- {name} ---\n{content[:5000]}" for name, content in project_data.items()])
        
        full_prompt = f"""
        Î•Î¯ÏƒÎ±Î¹ Î¿ Senior Architect (Mastro Nek). 
        Î Î›Î‘Î™Î£Î™ÎŸ: Î•Î¼Ï€Î¿ÏÎ¹ÎºÎ® ÎµÏ†Î±ÏÎ¼Î¿Î³Î® HVAC SaaS.
        Î£ÎšÎŸÎ ÎŸÎ£: {strategy} ÏƒÏ„Î¿ {focus_file}.
        
        ÎŸÎ”Î—Î“Î™Î•Î£:
        1. ÎœÎ¯Î»Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬.
        2. Î”ÏÏƒÎµ ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î©ÎœÎ•ÎÎŸ ÎºÏÎ´Î¹ÎºÎ± Î³Î¹Î± ÎºÎ¬Î¸Îµ Î±ÏÏ‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î±Î»Î»Î¬Î¶ÎµÎ¹Ï‚.
        3. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î‘ÎšÎ¡Î™Î’Î©Î£ Î±Ï…Ï„ÏŒ Ï„Î¿ format Î³Î¹Î± Î±ÏÏ‡ÎµÎ¯Î±:
        ### FILE: path/to/filename.py
        ```python
        (ÎºÏÎ´Î¹ÎºÎ±Ï‚)
        ```
        
        PROJECT CONTEXT:
        {context_summary}
        
        Î•ÎÎ¤ÎŸÎ›Î— Î§Î¡Î—Î£Î¤Î—: {user_prompt if user_prompt else "Î”ÎµÏ‚ Ï„Î± ÏƒÏ…Î½Î·Î¼Î¼Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î±/Î®Ï‡Î¿."}
        """

        parts = [full_prompt]
        if audio and audio['bytes']: parts.append({"mime_type": "audio/wav", "data": audio['bytes']})
        if uploaded: parts.append({"mime_type": uploaded.type, "data": uploaded.getvalue()})

        # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· AI
        with st.chat_message("assistant"):
            with st.spinner("ÎŸ Î‘ÏÏ‡Î¹Ï„Î­ÎºÏ„Î¿Î½Î±Ï‚ Î±Î½Î±Î»ÏÎµÎ¹ Ï„Î¿ project..."):
                response = run_ai_logic(parts, api_key)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                # Î•Ï€Î¹Î»Î¿Î³Î® Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚
                if "### FILE:" in response:
                    if auto_save:
                        st.code(apply_code_changes(response))
                        time.sleep(1)
                        st.rerun()
                    else:
                        if st.button("ğŸ’¾ Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î‘Î»Î»Î±Î³ÏÎ½ ÏƒÏ„Î¿ Project"):
                            log = apply_code_changes(response)
                            st.code(log)
                            st.success("ÎŸÎ¹ Î±Î»Î»Î±Î³Î­Ï‚ ÎµÏ†Î±ÏÎ¼ÏŒÏƒÏ„Î·ÎºÎ±Î½!")
                            time.sleep(1)
                            st.rerun()

if __name__ == "__main__":
    main()