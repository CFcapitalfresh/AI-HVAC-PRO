"""
SERVICE: AI SORTER LOGIC (DYNAMIC DISCOVERY EDITION)
----------------------------------------------------
Features:
- AUTO-DETECT MODEL: Î¡Ï‰Ï„Î¬ÎµÎ¹ Ï„Î·Î½ Google Ï€Î¿Î¹Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎµÎ¯Î½Î±Î¹ ÎµÎ½ÎµÏÎ³ÏŒ (Gemini 2.0, 1.5, Pro ÎºÎ»Ï€).
- NO HARDCODED NAMES: Î”ÎµÎ½ ÎºÏÎ±ÏƒÎ¬ÏÎµÎ¹ Î±Î½ Î±Î»Î»Î¬Î¾ÎµÎ¹ Î· Î¿Î½Î¿Î¼Î±ÏƒÎ¯Î±.
- 4-Level Sorting: Category > Brand > Model > Type
- ENHANCED FEEDBACK: Provides more detailed progress to the UI.
- CANCELLATION: Adds a mechanism to stop the sorting process.
- NEW: Irrelevant/Unknown File Handling
- NEW: Duplicate File Detection (Hashing)
- NEW: AI-driven File Renaming
- NEW: Enhanced Summary Reporting for UI
"""
import streamlit as st
from core.drive_manager import DriveManager
from core.config_loader import ConfigLoader
import google.generativeai as genai
import logging
import time
import io
import os
import pypdf
import re
import tempfile
import hashlib # ÎÎ•ÎŸ: Î“Î¹Î± Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒ hash
from collections import defaultdict # ÎÎ•ÎŸ: Î“Î¹Î± Ï€Î¹Î¿ ÎµÏÎºÎ¿Î»Î· ÎºÎ±Ï„Î±Î¼Î­Ï„ÏÎ·ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½
from datetime import datetime # ÎÎ•ÎŸ: Î“Î¹Î± timestamp

logger = logging.getLogger("Sorter")

ALLOWED_CATEGORIES = [
    "Heating_Boilers", "Heat_Pumps", "Air_Conditioning", "Solar_Systems", 
    "Water_Heaters", "Thermostats_Controllers", "Spare_Parts_Valves", "Other_HVAC"
]

ALLOWED_TYPES = [
    "User_Manual", "Service_Manual", "Installation_Manual", 
    "Technical_Data", "Error_Codes", "Spare_Parts_List", "General_Manual" # Added General_Manual
]

# ÎÎ•ÎŸÎ™ Î¦Î‘ÎšÎ•Î›ÎŸÎ™: Î“Î¹Î± Î¬ÏƒÏ‡ÎµÏ„Î±/Î¼Î· Î±Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÎ¹Î¼Î± ÎºÎ±Î¹ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±
IRRELEVANT_OR_UNKNOWN_FOLDER = "_IRRELEVANT_OR_UNKNOWN"
DUPLICATES_FOLDER = "_DUPLICATES"

# IGNORED_FOLDERS_TOP_LEVEL now includes the new special folders
IGNORED_FOLDERS_TOP_LEVEL = [
    "_MANUAL_REVIEW", 
    "_AI_ERROR", 
    "Trash", 
    "_NEEDS_OCR",
    IRRELEVANT_OR_UNKNOWN_FOLDER, # ÎÎ•ÎŸ
    DUPLICATES_FOLDER # ÎÎ•ÎŸ
]

class SorterService:
    def __init__(self):
        self.drive = DriveManager()
        self.api_key = ConfigLoader.get_gemini_key()
        self.model = None
        self.root_id = ConfigLoader.get_drive_folder_id() # Î•Î Î™Î”Î™ÎŸÎ¡Î˜Î©Î£Î—: Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ Î· Î±Î½Î¬ÎºÏ„Î·ÏƒÎ· Ï„Î¿Ï… root_id
        self._setup_ai()

    def _setup_ai(self):
        """DYNAMIC DISCOVERY: Î’ÏÎ¯ÏƒÎºÎµÎ¹ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿."""
        if self.api_key and not self.model: # Ensure we don't re-initialize if already done
            try:
                genai.configure(api_key=self.api_key)
                
                # 1. Î–Î·Ï„Î¬Î¼Îµ Î»Î¯ÏƒÏ„Î± Î±Ï€ÏŒ Ï„Î·Î½ Google
                available_models = []
                try:
                    for m in genai.list_models():
                        # ÎÎ•ÎŸ: Î•Î»Î­Î³Ï‡Î¿Ï…Î¼Îµ Î±Î½ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ Vision (Î³Î¹Î± PDF uploads)
                        if 'generateContent' in m.supported_generation_methods and 'uri' in m.input_token_limit_protos:
                            available_models.append(m.name)
                except Exception as e:
                    logger.warning(f"Could not list Gemini models during Sorter setup: {e}")

                # 2. Î›Î¯ÏƒÏ„Î± Î ÏÎ¿Ï„Î¯Î¼Î·ÏƒÎ·Ï‚ (Î±Ï€ÏŒ Ï„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿/Î½ÎµÏŒÏ„ÎµÏÎ¿ ÏƒÏ„Î¿ Ï€Î±Î»Î±Î¹ÏŒÏ„ÎµÏÎ¿, Î¼Îµ Ï€ÏÎ¿Ï„Î¯Î¼Î·ÏƒÎ· ÏƒÏ„Î± Vision-enabled)
                preferred_order = [
                    "gemini-1.5-pro", # Î ÏÎ¿Ï„Î¯Î¼Î·ÏƒÎ· ÏƒÏ„Î¿ Pro Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ·
                    "models/gemini-1.5-pro",
                    "gemini-1.5-flash", 
                    "models/gemini-1.5-flash",
                    "gemini-2.0-flash-exp", 
                    "models/gemini-2.0-flash-exp",
                    "gemini-pro",
                    "models/gemini-pro"
                ]
                
                selected_model = None
                
                # 3. ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î´Î¹Î±Î¸ÎµÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±Ï‚
                for p in preferred_order:
                    if p in available_models:
                        selected_model = p
                        break
                
                # 4. Fallback (Î‘Î½ Î´ÎµÎ½ Î²ÏÎµÎ¸ÎµÎ¯ ÎºÎ±Î½Î­Î½Î¿ Î±Ï€ÏŒ Ï„Î± Î±Î³Î±Ï€Î·Î¼Î­Î½Î±, Ï€Î¬ÏÎµ ÏŒ,Ï„Î¹ Î­Ï‡ÎµÎ¹ gemini ÎºÎ±Î¹ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÎ¹ content)
                if not selected_model:
                    for m in available_models:
                        if "gemini" in m:
                            selected_model = m
                            break
                
                if selected_model:
                    self.model = genai.GenerativeModel(selected_model)
                    logger.info(f"âœ… AI Initialized for Sorter using AUTO-DETECTED model: {selected_model}")
                else:
                    logger.error("âŒ No suitable Gemini models found available for Sorter with this API Key.")

            except Exception as e:
                logger.error(f"âŒ AI Init Error for Sorter: {e}", exc_info=True)

    def _calculate_file_hash(self, file_bytes):
        """Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¿ SHA256 hash Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…."""
        if file_bytes is None:
            return None
        return hashlib.sha256(file_bytes).hexdigest()

    def _extract_text_from_pdf(self, file_id):
        """Î•Î¾Î¬Î³ÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎºÎ±Î¹ bytes Î±Ï€ÏŒ PDF, Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶Î¿Î½Ï„Î±Ï‚ ÎºÎ±Î¹ Ï„Î¿ hash."""
        try:
            stream = self.drive.download_file_content(file_id)
            if not stream: return None, None, None
            stream.seek(0)
            file_bytes = stream.read()
            
            # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ hash
            file_hash = self._calculate_file_hash(file_bytes)

            reader = pypdf.PdfReader(io.BytesIO(file_bytes))
            text = ""
            for i in range(min(8, len(reader.pages))): # Scan first 8 pages for text
                text += reader.pages[i].extract_text() or ""
            return text[:5000], file_bytes, file_hash # Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ ÎºÎ±Î¹ Ï„Î¿ hash
        except Exception as e:
            logger.warning(f"Failed to extract text/hash from PDF (file_id: {file_id}): {e}")
            return None, None, None

    def _classify_with_vision(self, filename, file_bytes):
        """ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¹ÎµÎ¯ PDF Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Gemini Vision (Î³Î¹Î± ÏƒÎºÎ±Î½Î±ÏÎ¹ÏƒÎ¼Î­Î½Î± Î® Î´ÏÏƒÎºÎ¿Î»Î± PDFs)."""
        if not self.model: return None
        uploaded_file = None
        temp_path = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(file_bytes)
                temp_path = tmp.name
            
            uploaded_file = genai.upload_file(temp_path, mime_type="application/pdf")
            
            # ÎˆÎ¾Ï…Ï€Î½Î· Î±Î½Î±Î¼Î¿Î½Î®: Î ÎµÏÎ¹Î¼Î­Î½Î¿Ï…Î¼Îµ Î¼Î­Ï‡ÏÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Î­Ï„Î¿Î¹Î¼Î¿ (Î±Î½Ï„Î¯ Î³Î¹Î± fixed sleep)
            for _ in range(30): # Max 30 seconds wait for upload to activate
                file_status = genai.get_file(uploaded_file.name)
                if file_status.state.name == "ACTIVE":
                    break
                time.sleep(1)
            else: # If loop finishes without breaking
                raise TimeoutError("File upload to Gemini API timed out.")
            
            categories_str = ", ".join(ALLOWED_CATEGORIES)
            types_str = ", ".join(ALLOWED_TYPES)
            
            prompt = f"""
            TASK: Analyze this document for HVAC classification, even if it's a scanned image.
            FILENAME: {filename}
            RULES:
            1. IS_HVAC_MANUAL: Is this document an HVAC related manual (heating, cooling, ventilation)? Answer TRUE or FALSE. If FALSE, output only "NOT_HVAC_MANUAL|UNKNOWN|UNKNOWN|UNKNOWN|NO_HVAC_MANUAL".
            2. CATEGORY: If IS_HVAC_MANUAL is TRUE, choose one from [{categories_str}]. Fallback: 'Other_HVAC'.
            3. BRAND: If IS_HVAC_MANUAL is TRUE, identify Manufacturer (UPPERCASE). If not found, use "UNKNOWN".
            4. MODEL: If IS_HVAC_MANUAL is TRUE, identify Series/Model Name. If not found, use "MISC".
            5. TYPE: If IS_HVAC_MANUAL is TRUE, choose one from [{types_str}]. Fallback: 'General_Manual'.
            6. SUGGESTED_FILENAME: Based on BRAND, MODEL, TYPE (e.g., DAIKIN_ALTHERMA_SERVICE_MANUAL). Do NOT include extension.
            OUTPUT FORMAT: IS_HVAC_MANUAL|Category|Brand|Model|Type|Suggested_Filename
            """
            response = self.model.generate_content([prompt, uploaded_file], safety_settings={'HARASSMENT': 'BLOCK_NONE', 'HATE_SPEECH': 'BLOCK_NONE', 'SEXUALLY_EXPLICIT': 'BLOCK_NONE', 'DANGEROUS_CONTENT': 'BLOCK_NONE'})
            return response.text.strip()
        except Exception as e:
            logger.warning(f"Vision Classification Error for '{filename}': {e}", exc_info=True)
            return None
        finally:
            if uploaded_file:
                try: genai.delete_file(uploaded_file.name)
                except Exception as e: logger.warning(f"Failed to delete uploaded file {uploaded_file.name}: {e}")
            if temp_path and os.path.exists(temp_path):
                os.remove(temp_path)

    def _classify(self, filename, text, file_bytes):
        """ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¹ÎµÎ¯ Î±ÏÏ‡ÎµÎ¯Î¿, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Î±ÏÏ‡Î¹ÎºÎ¬ ÎºÎµÎ¯Î¼ÎµÎ½Î¿, fallback ÏƒÎµ Vision."""
        if not self.model: 
            logger.error("AI model not initialized for classification.")
            return {
                "is_hvac_manual": False,
                "category": IRRELEVANT_OR_UNKNOWN_FOLDER,
                "brand": "UNKNOWN",
                "model": "MISC",
                "type": "General_Manual",
                "suggested_filename": self._normalize(filename.replace('.pdf', '') + "_UNCATEGORIZED")
            }
        
        classification_raw_output = None
        
        # TEXT MODE (Prioritize if enough text)
        if text and len(text.strip()) > 100: # Î±Ï…Î¾Î·ÏƒÎ± Ï„Î¿ ÏŒÏÎ¹Î¿ Î³Î¹Î± Ï€Î¹Î¿ Î±Î¾Î¹Î¿Ï€Î¹ÏƒÏ„Î· Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ·
            categories_str = ", ".join(ALLOWED_CATEGORIES)
            types_str = ", ".join(ALLOWED_TYPES)
            prompt = f"""
            TASK: Classify this HVAC document.
            FILENAME: {filename}
            SAMPLE (first 1000 chars): {text[:1000]}
            RULES:
            1. IS_HVAC_MANUAL: Is this document an HVAC related manual (heating, cooling, ventilation)? Answer TRUE or FALSE. If FALSE, output only "NOT_HVAC_MANUAL|UNKNOWN|UNKNOWN|UNKNOWN|NO_HVAC_MANUAL".
            2. CATEGORY: If IS_HVAC_MANUAL is TRUE, choose one from [{categories_str}]. Fallback: 'Other_HVAC'.
            3. BRAND: If IS_HVAC_MANUAL is TRUE, identify Manufacturer (UPPERCASE). If not found, use "UNKNOWN".
            4. MODEL: If IS_HVAC_MANUAL is TRUE, identify Series/Model Name. If not found, use "MISC".
            5. TYPE: If IS_HVAC_MANUAL is TRUE, choose one from [{types_str}]. Fallback: 'General_Manual'.
            6. SUGGESTED_FILENAME: If IS_HVAC_MANUAL is TRUE, generate a concise filename based on BRAND, MODEL, TYPE (e.g., DAIKIN_ALTHERMA_SERVICE_MANUAL). Do NOT include extension. If IS_HVAC_MANUAL is FALSE, set to "NO_HVAC_MANUAL".
            OUTPUT FORMAT: IS_HVAC_MANUAL|Category|Brand|Model|Type|Suggested_Filename
            """
            try:
                response = self.model.generate_content(prompt, safety_settings={'HARASSMENT': 'BLOCK_NONE', 'HATE_SPEECH': 'BLOCK_NONE', 'SEXUALLY_EXPLICIT': 'BLOCK_NONE', 'DANGEROUS_CONTENT': 'BLOCK_NONE'})
                classification_raw_output = response.text.strip()
            except Exception as e:
                logger.warning(f"Text Classification Error for '{filename}': {e}. Falling back to Vision if bytes available.", exc_info=True)
        
        # VISION MODE FALLBACK if text classification failed or returned nothing
        if not classification_raw_output and file_bytes:
            logger.info(f"ğŸ‘ï¸ Vision Mode Triggered for: {filename} (Text classification failed)")
            classification_raw_output = self._classify_with_vision(filename, file_bytes)
            
        # Parse output
        if classification_raw_output and "|" in classification_raw_output:
            parts = [p.strip() for p in classification_raw_output.split("|")]
            if len(parts) >= 6:
                is_hvac_manual_str, category_raw, brand_raw, model_raw, doc_type_raw, suggested_filename_raw = parts
                
                is_hvac_manual = (is_hvac_manual_str.upper() == "TRUE")

                if not is_hvac_manual:
                    category_final = IRRELEVANT_OR_UNKNOWN_FOLDER
                    brand_final = "UNKNOWN"
                    model_final = "MISC"
                    doc_type_final = "General_Manual"
                    suggested_filename_final = self._normalize(filename.replace('.pdf', '') + "_NOT_HVAC")
                else:
                    category_final = self._normalize(category_raw)
                    brand_final = self._normalize(brand_raw)
                    model_final = self._normalize(model_raw)
                    doc_type_final = self._normalize(doc_type_raw)
                    suggested_filename_final = self._normalize(suggested_filename_raw) if suggested_filename_raw else self._normalize(f"{brand_final}_{model_final}_{doc_type_final}")

                    # Apply fallbacks if normalization results in empty string or unallowed values
                    if not category_final or category_final not in ALLOWED_CATEGORIES: category_final = "Other_HVAC"
                    if not brand_final: brand_final = "UNKNOWN"
                    if not model_final: model_final = "MISC"
                    if not doc_type_final or doc_type_final not in ALLOWED_TYPES: doc_type_final = "General_Manual"
                    if not suggested_filename_final: suggested_filename_final = self._normalize(filename.replace('.pdf', '') + "_RENAMED")

                return {
                    "is_hvac_manual": is_hvac_manual,
                    "category": category_final,
                    "brand": brand_final,
                    "model": model_final,
                    "type": doc_type_final,
                    "suggested_filename": suggested_filename_final
                }
            elif classification_raw_output.upper().startswith("NOT_HVAC_MANUAL"):
                logger.info(f"AI classified {filename} as NOT_HVAC_MANUAL.")
                return {
                    "is_hvac_manual": False,
                    "category": IRRELEVANT_OR_UNKNOWN_FOLDER,
                    "brand": "UNKNOWN",
                    "model": "MISC",
                    "type": "General_Manual",
                    "suggested_filename": self._normalize(filename.replace('.pdf', '') + "_NOT_HVAC")
                }
            else:
                logger.warning(f"AI output for '{filename}' was unparseable or incomplete: {classification_raw_output}. Falling back to defaults.")
        else:
            logger.warning(f"No AI output for '{filename}'. Falling back to defaults.")

        # Default fallback if all else fails
        return {
            "is_hvac_manual": False, # Assume not an HVAC manual if classification failed
            "category": IRRELEVANT_OR_UNKNOWN_FOLDER, # Send to irrelevant for manual review
            "brand": "UNKNOWN",
            "model": "MISC",
            "type": "General_Manual",
            "suggested_filename": self._normalize(filename.replace('.pdf', '') + "_UNCATEGORIZED")
        }

    def _normalize(self, name):
        """
        ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ ÎºÎ±Î¹ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¹ÎµÎ¯ Î­Î½Î± ÏŒÎ½Î¿Î¼Î± Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· ÏƒÎµ Ï†Î¬ÎºÎµÎ»Î¿ Î® ÏŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï….
        Î•Ï€Î¯ÏƒÎ·Ï‚, ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î­Î½Î± default string Î±Î½ Ï„Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½ÏŒ.
        """
        if not isinstance(name, str):
            name = str(name)
        
        # Î‘Ï†Î±Î¹ÏÎµÎ¯ Î¼Î· ÎµÏ€Î¹Ï„ÏÎµÏ€Ï„Î¿ÏÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ Î¿Î½ÏŒÎ¼Î±Ï„Î¿Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…/Î±ÏÏ‡ÎµÎ¯Î¿Ï…
        normalized = re.sub(r'[\\/*?:"<>|]', "", name).strip()
        
        # Î‘Î½Ï„Î¹ÎºÎ±Î¸Î¹ÏƒÏ„Î¬ ÎºÎµÎ½Î¬ Î¼Îµ underscores Î³Î¹Î± Î¿Î½ÏŒÎ¼Î±Ï„Î± Î±ÏÏ‡ÎµÎ¯Ï‰Î½
        normalized = re.sub(r'\s+', '_', normalized)

        # Î•Ï€Î¯ÏƒÎ·Ï‚, Î±Î½ Ï„Î¿ ÏŒÎ½Î¿Î¼Î± ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½ÏŒ Î¼ÎµÏ„Î¬ Ï„Î¿Î½ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒ, ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ "UNKNOWN"
        if not normalized:
            return "UNKNOWN" 
        return normalized

    def _scan_recursively(self, folder_id, path_parts=None, depth=0):
        """
        Î‘Î½Î±Î´ÏÎ¿Î¼Î¹ÎºÎ® ÏƒÎ¬ÏÏ‰ÏƒÎ· Ï†Î±ÎºÎ­Î»Ï‰Î½, ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Î½Ï„Î±Ï‚ Î¼ÏŒÎ½Î¿ PDFs Ï€Î¿Ï… Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î±
        ÎµÎ½Ï„ÏŒÏ‚ Ï„Ï‰Î½ ALLOWED_CATEGORIES Î® Ï„Ï‰Î½ IGNORED_FOLDERS_TOP_LEVEL.
        """
        if path_parts is None:
            path_parts = []

        found_pdfs = []
        if depth > 5: # Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î²Î¬Î¸Î¿Ï…Ï‚ Î³Î¹Î± Î±Ï€Î¿Ï†Ï…Î³Î® Î¬Ï€ÎµÎ¹ÏÎ·Ï‚ Î±Î½Î±Î´ÏÎ¿Î¼Î®Ï‚
            logger.warning(f"Reached max recursion depth for folder {folder_id}.")
            return [] 

        try:
            items = self.drive.list_files_in_folder(folder_id)
            for item in items:
                current_path_parts = path_parts + [item['name']]

                # Check if we are inside an already categorized folder or an ignored folder
                is_already_categorized_branch = False
                if depth >= 1 and path_parts[0] in ALLOWED_CATEGORIES:
                    is_already_categorized_branch = True
                
                # ÎÎ•ÎŸ: Î•Î»Î­Î³Ï‡Î¿Ï…Î¼Îµ Î±Î½ ÎµÎ¯Î½Î±Î¹ ÏƒÎµ ÎºÎ¬Ï€Î¿Î¹Î¿Î½ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ IGNORED_FOLDERS_TOP_LEVEL
                # Î‘Ï…Ï„ÏŒ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Î±Î½ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÎµ Î­Î½Î±Î½ Î±Ï€ÏŒ Î±Ï…Ï„Î¿ÏÏ‚ Ï„Î¿Ï…Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚
                # Î´ÎµÎ½ Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Ï„Î¿ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÏ„Î¿ÏÎ¼Îµ Î¾Î±Î½Î¬ Ï‰Ï‚ "Î¼Î· Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î¿".
                is_in_ignored_folder = False
                if depth >= 1 and path_parts[0] in IGNORED_FOLDERS_TOP_LEVEL:
                    is_in_ignored_folder = True

                if item['mimeType'] == 'application/pdf':
                    # Only add PDF if it's NOT in an already categorized branch AND NOT in an ignored folder
                    if not is_already_categorized_branch and not is_in_ignored_folder:
                        item['full_path_context'] = " | ".join(current_path_parts)
                        found_pdfs.append(item)
                elif item['mimeType'] == 'application/vnd.google-apps.folder':
                    # Skip scanning certain top-level ignored folders or already categorized branches
                    if item['name'] in IGNORED_FOLDERS_TOP_LEVEL:
                        logger.info(f"ğŸ“‚ Skipping ignored top-level folder during scan: {item['name']}")
                        continue
                    if item['name'] in ALLOWED_CATEGORIES and depth == 0:
                        logger.info(f"ğŸ“‚ Skipping already sorted category folder during scan: {item['name']}")
                        continue
                    
                    logger.info(f"ğŸ“‚ Scanning subfolder: {'/'.join(current_path_parts)}")
                    found_pdfs.extend(self._scan_recursively(item['id'], current_path_parts, depth + 1))
        except Exception as e:
            logger.error(f"Error during recursive scan in folder {folder_id} (path: {'/'.join(path_parts)}): {e}", exc_info=True)
        return found_pdfs

    def process_unsorted_files(self, status_callback, specific_file_id=None, manual_inputs=None):
        """
        Î•Ï€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Î¼Î· Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î± PDF.
        Î•Î¬Î½ Ï€Î±ÏÎ­Ï‡Î¿Î½Ï„Î±Î¹ specific_file_id ÎºÎ±Î¹ manual_inputs, ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Î¼ÏŒÎ½Î¿ Î±Ï…Ï„ÏŒ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿.
        """
        logger.info("ğŸš€ Starting Dynamic AI Sort...")
        if not self.root_id: 
            status_callback("Root Drive Folder ID is missing. Please configure.", "error")
            return

        # ÎÎ•ÎŸ: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎµÎ¹Î´Î¹ÎºÏÎ½ Ï†Î±ÎºÎ­Î»Ï‰Î½ Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½
        irrelevant_folder_id = self.drive.create_folder(IRRELEVANT_OR_UNKNOWN_FOLDER, self.root_id)
        duplicates_folder_id = self.drive.create_folder(DUPLICATES_FOLDER, self.root_id)
        manual_review_root_id = self.drive.create_folder("_MANUAL_REVIEW", self.root_id) # Ensure this also exists
        
        if not irrelevant_folder_id or not duplicates_folder_id or not manual_review_root_id:
            status_callback(f"âŒ Î‘Î´Ï…Î½Î±Î¼Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ ÎµÎ½ÏŒÏ‚ Î® Ï€ÎµÏÎ¹ÏƒÏƒÎ¿Ï„Î­ÏÏ‰Î½ ÎµÎ¹Î´Î¹ÎºÏÎ½ Ï†Î±ÎºÎ­Î»Ï‰Î½.", "error")
            return

        pdfs_to_process = []
        if specific_file_id:
            # If reprocessing a specific file, fetch its data directly
            try:
                # Find the file in its current parent (could be any folder)
                file_metadata = self.drive.service.files().get(fileId=specific_file_id, fields='id, name, mimeType, webViewLink, parents').execute()
                if file_metadata:
                    # Check if it's a PDF
                    if file_metadata['mimeType'] == 'application/pdf':
                        # Make sure it has 'full_path_context' for consistent processing, though not strictly needed for manual
                        file_metadata['full_path_context'] = file_metadata['name'] # Simple name as context for reprocessed
                        pdfs_to_process.append(file_metadata)
                    else:
                        status_callback(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î¼Îµ ID '{specific_file_id}' Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ PDF.", "error")
                        return
                else:
                    status_callback(f"Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î¼Îµ ID '{specific_file_id}' Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î³Î¹Î± ÎµÏ€Î±Î½ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±.", "error")
                    return
            except Exception as e:
                logger.error(f"Error fetching specific file {specific_file_id}: {e}", exc_info=True)
                status_callback(f"Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï… '{specific_file_id}': {e}", "error")
                return
        else:
            all_pdfs = self._scan_recursively(self.root_id)
            pdfs_to_process = all_pdfs 

        if not pdfs_to_process:
            status_callback("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÏ‡ÎµÎ¯Î± PDF Î³Î¹Î± Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· Î® ÏŒÎ»Î± ÎµÎ¯Î½Î±Î¹ Î®Î´Î· Ï„Î±Î¾Î¹Î½Î¿Î¼Î·Î¼Î­Î½Î±.", "success")
            # ÎÎ•ÎŸ: Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î±ÎºÏŒÎ¼Î± ÎºÎ±Î¹ Î±Î½ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÏ‡ÎµÎ¯Î±
            st.session_state['sorter_summary'] = {
                'last_run_timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'total_files_scanned': 0,
                'total_successfully_sorted': 0,
                'total_moved_to_manual_review': len(st.session_state.get('sorter_manual_review_files', [])),
                'total_moved_to_irrelevant': len(st.session_state.get('sorter_irrelevant_files', [])),
                'total_moved_to_duplicates': len(st.session_state.get('sorter_duplicate_files', [])),
                'category_counts': {},
                'brand_counts': {},
                'type_counts': {}
            }
            return

        status_callback(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(pdfs_to_process)} Î±ÏÏ‡ÎµÎ¯Î± Î³Î¹Î± Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·. ÎˆÎ½Î±ÏÎ¾Î·...", "info")
        success_count = 0
        
        total_files = len(pdfs_to_process)

        # ÎÎ•ÎŸ: ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î»Î¹ÏƒÏ„ÏÎ½ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î® Ï„Î·Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ (Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î±ÏÏ‡ÎµÎ¯Î¿)
        if not specific_file_id:
            st.session_state['sorter_failed_files'] = []
            st.session_state['sorter_manual_review_files'] = []
            st.session_state['sorter_irrelevant_files'] = [] # ÎÎ•ÎŸ
            st.session_state['sorter_duplicate_files'] = []  # ÎÎ•ÎŸ
            st.session_state['sorter_run_log'] = []
            
            # ÎÎ•ÎŸ: Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î³Î¹Î± Î±Ï…Ï„Î® Ï„Î·Î½ ÎµÎºÏ„Î­Î»ÎµÏƒÎ·
            # Î‘Ï…Ï„Î¬ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸Î¿ÏÎ½ Î³Î¹Î± Î½Î± ÎµÎ½Î·Î¼ÎµÏÏ‰Î¸ÎµÎ¯ Ï„Î¿ st.session_state['sorter_summary'] ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚
            current_run_stats = {
                'total_files_scanned': total_files,
                'total_successfully_sorted': 0,
                'total_moved_to_manual_review': 0,
                'total_moved_to_irrelevant': 0,
                'total_moved_to_duplicates': 0,
                'category_counts': defaultdict(int),
                'brand_counts': defaultdict(int),
                'type_counts': defaultdict(int)
            }
        else: # If it's a specific file, we need to load existing stats or init
            if 'sorter_summary' not in st.session_state or not st.session_state['sorter_summary']:
                # Initialise if no previous run or stats were cleared
                current_run_stats = {
                    'total_files_scanned': total_files, # For this specific run it's just 1
                    'total_successfully_sorted': 0,
                    'total_moved_to_manual_review': 0,
                    'total_moved_to_irrelevant': 0,
                    'total_moved_to_duplicates': 0,
                    'category_counts': defaultdict(int),
                    'brand_counts': defaultdict(int),
                    'type_counts': defaultdict(int)
                }
            else:
                # Use existing summary as base
                current_run_stats = {k: v for k, v in st.session_state['sorter_summary'].items() if k != 'last_run_timestamp'}
                current_run_stats['category_counts'] = defaultdict(int, current_run_stats['category_counts'])
                current_run_stats['brand_counts'] = defaultdict(int, current_run_stats['brand_counts'])
                current_run_stats['type_counts'] = defaultdict(int, current_run_stats['type_counts'])
                current_run_stats['total_files_scanned'] += total_files # Add the single file to total scanned


        
        if 'sorter_progress_data' not in st.session_state:
            st.session_state.sorter_progress_data = {"current": 0, "total": total_files, "text": ""}

        # ÎÎ•ÎŸ: Î›ÎµÎ¾Î¹ÎºÏŒ Î³Î¹Î± hashes Î³Î¹Î± ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Ï‰Î½
        # hash_value -> {'original_file_id': id, 'original_file_name': name}
        processed_hashes = {} 

        for i, pdf in enumerate(pdfs_to_process):
            if st.session_state.get('sorter_stop_flag', False) and not specific_file_id:
                status_callback("Î”Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·Ï‚ Î±ÎºÏ…ÏÏÎ¸Î·ÎºÎµ Î±Ï€ÏŒ Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î·.", "warning")
                logger.info("Sorter process cancelled by user.")
                st.session_state['sorter_stop_flag'] = False # Reset flag
                return # Exit the function

            st.session_state.sorter_progress_data["current"] = i + 1
            st.session_state.sorter_progress_data["total"] = total_files
            st.session_state.sorter_progress_data["text"] = f"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± {i+1} / {total_files}: **{pdf['name']}**"
            status_callback(f"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ({i+1}/{total_files}): {pdf['name']}", "info")
            logger.info(f"Processing file: {pdf['name']} ({pdf['id']})")

            classification_output_raw = "No AI output" # Default for logging
            
            try:
                text_content, bytes_data, file_hash = self._extract_text_from_pdf(pdf['id'])
                if file_hash is None:
                    status_callback(f"âŒ Î‘Î´Ï…Î½Î±Î¼Î¯Î± ÎµÎ¾Î±Î³Ï‰Î³Î®Ï‚ Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï…/hash Î³Î¹Î± '{pdf['name']}'.", "error")
                    st.session_state['sorter_failed_files'].append({"file": pdf, "reason": "Content/Hash extraction failed", "output": "N/A"})
                    continue

                # ÎÎ•ÎŸ: ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±
                if not specific_file_id and file_hash in processed_hashes:
                    original_info = processed_hashes[file_hash]
                    status_callback(f"âš ï¸ Î’ÏÎ­Î¸Î·ÎºÎµ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î¿: '{pdf['name']}'. Î¤Î¿ Ï€ÏÏ‰Ï„ÏŒÏ„Ï…Ï€Î¿ ÎµÎ¯Î½Î±Î¹ '{original_info['original_file_name']}'.", "warning")
                    if self.drive.move_file(pdf['id'], duplicates_folder_id):
                        st.session_state['sorter_duplicate_files'].append({
                            "file": pdf, 
                            "reason": f"Duplicate of {original_info['original_file_name']}", 
                            "output": f"Original ID: {original_info['original_file_id']}"
                        })
                        logger.info(f"Moved duplicate file {pdf['name']} to '{DUPLICATES_FOLDER}'.")
                        current_run_stats['total_moved_to_duplicates'] += 1
                    else:
                        status_callback(f"âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î¼ÎµÏ„Î±ÎºÎ¯Î½Î·ÏƒÎ·Ï‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î¿Ï… '{pdf['name']}'.", "error")
                        st.session_state['sorter_failed_files'].append({"file": pdf, "reason": "Failed to move duplicate", "output": "N/A"})
                    continue
                elif not specific_file_id:
                    processed_hashes[file_hash] = {'original_file_id': pdf['id'], 'original_file_name': pdf['name']}


                classification_result = {}
                if manual_inputs: # If manual inputs are provided for reprocessing
                    classification_result = {
                        "is_hvac_manual": True, # Assume true if manually reprocessing
                        "category": self._normalize(manual_inputs.get('category')),
                        "brand": self._normalize(manual_inputs.get('brand')),
                        "model": self._normalize(manual_inputs.get('model')),
                        "type": self._normalize(manual_inputs.get('type')),
                        "suggested_filename": self._normalize(f"{manual_inputs.get('brand')}_{manual_inputs.get('model')}_{manual_inputs.get('type')}")
                    }
                    classification_output_raw = f"Manual Input: {classification_result['category']}|{classification_result['brand']}|{classification_result['model']}|{classification_result['type']}"
                    logger.info(f"Using manual inputs for file {pdf['name']}: {classification_output_raw}")
                else:
                    classification_result = self._classify(pdf['name'], text_content, bytes_data)
                    classification_output_raw = f"AI Output: {classification_result['is_hvac_manual']}|{classification_result['category']}|{classification_result['brand']}|{classification_result['model']}|{classification_result['type']}|{classification_result['suggested_filename']}"


                # ÎÎ•ÎŸ: ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± Î¬ÏƒÏ‡ÎµÏ„Î±/Î¼Î· Î±Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÎ¹Î¼Î± Î±ÏÏ‡ÎµÎ¯Î±
                if not classification_result["is_hvac_manual"]:
                    status_callback(f"âš ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ '{pdf['name']}' Î´ÎµÎ½ Î±Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÏ„Î·ÎºÎµ Ï‰Ï‚ manual HVAC. ÎœÎµÏ„Î±ÎºÎ¯Î½Î·ÏƒÎ· ÏƒÎµ '{IRRELEVANT_OR_UNKNOWN_FOLDER}'.", "warning")
                    if self.drive.move_file(pdf['id'], irrelevant_folder_id):
                        st.session_state['sorter_irrelevant_files'].append({"file": pdf, "reason": "Not an HVAC manual", "output": classification_output_raw})
                        logger.info(f"Moved irrelevant file {pdf['name']} to '{IRRELEVANT_OR_UNKNOWN_FOLDER}'.")
                        current_run_stats['total_moved_to_irrelevant'] += 1
                    else:
                        status_callback(f"âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î¼ÎµÏ„Î±ÎºÎ¯Î½Î·ÏƒÎ·Ï‚ Î¬ÏƒÏ‡ÎµÏ„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… '{pdf['name']}'.", "error")
                        st.session_state['sorter_failed_files'].append({"file": pdf, "reason": "Failed to move irrelevant file", "output": classification_output_raw})
                    continue # Î ÏÎ¿Ï‡Ï‰ÏÎ¬Î¼Îµ ÏƒÏ„Î¿ ÎµÏ€ÏŒÎ¼ÎµÎ½Î¿ Î±ÏÏ‡ÎµÎ¯Î¿

                # Î•Î»Î­Î³Ï‡Î¿Ï…Î¼Îµ Î±Î½ Ï„Î¿ AI Ï€ÏÏŒÏ„ÎµÎ¹Î½Îµ "manual review" Î»ÏŒÎ³Ï‰ Î±ÏƒÎ±Ï†ÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
                if classification_result["category"] == "_MANUAL_REVIEW":
                    status_callback(f"âš ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ '{pdf['name']}' Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Ï‡ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î· Î±Î½Î±Î¸ÎµÏÏÎ·ÏƒÎ· (Î‘Î™ Ï€ÏÏŒÏ„Î±ÏƒÎ·).", "warning")
                    # Move to the _MANUAL_REVIEW folder (which is a top-level folder)
                    
                    if manual_review_root_id and self.drive.move_file(pdf['id'], manual_review_root_id):
                        st.session_state['sorter_manual_review_files'].append({"file": pdf, "reason": "AI suggested manual review", "output": classification_output_raw})
                        logger.info(f"Moved file {pdf['name']} to '_MANUAL_REVIEW' based on AI suggestion.")
                        current_run_stats['total_moved_to_manual_review'] += 1
                    else:
                        status_callback(f"âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î¼ÎµÏ„Î±ÎºÎ¯Î½Î·ÏƒÎ·Ï‚ '{pdf['name']}' ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ Ï‡ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î·Ï‚ Î±Î½Î±Î¸ÎµÏÏÎ·ÏƒÎ·Ï‚.", "error")
                        st.session_state['sorter_failed_files'].append({"file": pdf, "reason": "Failed to move to manual review folder", "output": classification_raw_output})
                    continue

                # ÎÎ•ÎŸ: ÎœÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…
                new_filename = f"{classification_result['suggested_filename']}.pdf"
                if new_filename != pdf['name']: # Only rename if different
                    if self.drive.rename_file(pdf['id'], new_filename):
                        logger.info(f"Renamed '{pdf['name']}' to '{new_filename}'.")
                        pdf['name'] = new_filename # Update name in current pdf dict for subsequent steps
                        status_callback(f"âœ… ÎœÎµÏ„Î¿Î½Î¿Î¼Î¬ÏƒÏ„Î·ÎºÎµ: '{pdf['name']}' ÏƒÎµ '{new_filename}'.", "success")
                    else:
                        status_callback(f"âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î¼ÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯Î±Ï‚ '{pdf['name']}'.", "error")
                        # Do not block further processing, continue with original name if rename fails
                
                # 4-LEVEL FOLDERS - ÎŸÏ…ÏƒÎ¹Î±ÏƒÏ„Î¹ÎºÎ® Î¤Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ·
                current_parent_id = self.root_id
                
                # Create Category Folder
                cat_folder_name = classification_result['category']
                cat_id = self.drive.create_folder(cat_folder_name, current_parent_id)
                if not cat_id:
                    status_callback(f"âŒ Failed to create Category folder: {cat_folder_name} for '{pdf['name']}'.", "error")
                    st.session_state['sorter_failed_files'].append({"file": pdf, "reason": "Category folder creation failed", "output": classification_output_raw})
                    continue
                current_parent_id = cat_id
                
                # Create Brand Folder
                brand_id = self.drive.create_folder(classification_result['brand'], current_parent_id)
                if not brand_id:
                    status_callback(f"âš ï¸ Failed to create Brand folder: {classification_result['brand']} for '{pdf['name']}'. Placing in category root.", "warning")
                else:
                    current_parent_id = brand_id
                    # Create Model Folder
                    model_id = self.drive.create_folder(classification_result['model'], current_parent_id)
                    if not model_id:
                        status_callback(f"âš ï¸ Failed to create Model folder: {classification_result['model']} for '{pdf['name']}'. Placing in Brand root.", "warning")
                    else:
                        current_parent_id = model_id
                        # Create Type Folder
                        type_id = self.drive.create_folder(classification_result['type'], current_parent_id)
                        if not type_id:
                            status_callback(f"âš ï¸ Failed to create Type folder: {classification_result['type']} for '{pdf['name']}'. Placing in Model root.", "warning")
                        else:
                            current_parent_id = type_id

                # MOVE
                # Ensure the file is not already in the target folder to prevent unnecessary moves
                file_metadata = self.drive.service.files().get(fileId=pdf['id'], fields='parents').execute()
                current_parents = file_metadata.get('parents', [])

                if current_parent_id not in current_parents:
                    if self.drive.move_file(pdf['id'], current_parent_id):
                        logger.info(f"âœ… Sorted: {cat_folder_name}/{classification_result['brand']}/{classification_result['model']}/{classification_result['type']} -> {pdf['name']}")
                        status_callback(f"âœ… Î¤Î±Î¾Î¹Î½Î¿Î¼Î®Î¸Î·ÎºÎµ: {cat_folder_name}/{classification_result['brand']}/{classification_result['model']}/{classification_result['type']} -> {pdf['name']}", "success")
                        success_count += 1
                        # Update current run stats
                        current_run_stats['total_successfully_sorted'] += 1
                        current_run_stats['category_counts'][classification_result['category']] += 1
                        current_run_stats['brand_counts'][classification_result['brand']] += 1
                        current_run_stats['type_counts'][classification_result['type']] += 1

                        # Remove from failed/manual review lists if it was successfully moved
                        # This also covers cases where it was moved from irrelevant/duplicate folders
                        st.session_state['sorter_failed_files'] = [f for f in st.session_state['sorter_failed_files'] if f['file']['id'] != pdf['id']]
                        st.session_state['sorter_manual_review_files'] = [f for f in st.session_state['sorter_manual_review_files'] if f['file']['id'] != pdf['id']]
                        st.session_state['sorter_irrelevant_files'] = [f for f in st.session_state['sorter_irrelevant_files'] if f['file']['id'] != pdf['id']]
                        st.session_state['sorter_duplicate_files'] = [f for f in st.session_state['sorter_duplicate_files'] if f['file']['id'] != pdf['id']]

                    else:
                        status_callback(f"âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î¼ÎµÏ„Î±ÎºÎ¯Î½Î·ÏƒÎ·Ï‚ '{pdf['name']}'.", "error")
                        st.session_state['sorter_failed_files'].append({"file": pdf, "reason": "File move failed", "output": classification_output_raw})
                else:
                    logger.info(f"â„¹ï¸ File '{pdf['name']}' already in target folder: {cat_folder_name}/{classification_result['brand']}/{classification_result['model']}/{classification_result['type']}. Skipping move.")
                    status_callback(f"â„¹ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ '{pdf['name']}' ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ„Î¿Î½ Ï€ÏÎ¿Î¿ÏÎ¹ÏƒÎ¼ÏŒ. Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ·.", "info")


                # Small delay to avoid hitting API rate limits
                time.sleep(0.5) 

            except Exception as e:
                logger.error(f"ğŸ”¥ Critical Error processing '{pdf['name']}': {e}", exc_info=True)
                status_callback(f"âŒ ÎšÏÎ¯ÏƒÎ¹Î¼Î¿ ÏƒÏ†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± '{pdf['name']}': {e}", "error")
                st.session_state['sorter_failed_files'].append({"file": pdf, "reason": f"Critical error: {e}", "output": classification_output_raw})

        st.session_state.sorter_progress_data["current"] = total_files # Mark as 100%
        final_message = f"ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î¤Î±Î¾Î¹Î½Î¿Î¼Î®Î¸Î·ÎºÎ±Î½: {success_count} / {total_files} Î±ÏÏ‡ÎµÎ¯Î±."
        if st.session_state['sorter_failed_files']:
            final_message += f" âŒ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯ÎµÏ‚: {len(st.session_state['sorter_failed_files'])}."
        if st.session_state['sorter_manual_review_files']:
            final_message += f" âš ï¸ Î§ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î· Î±Î½Î±Î¸ÎµÏÏÎ·ÏƒÎ·: {len(st.session_state['sorter_manual_review_files'])}."
        if st.session_state['sorter_irrelevant_files']:
            final_message += f" ğŸš« Î†ÏƒÏ‡ÎµÏ„Î±/Î†Î³Î½Ï‰ÏƒÏ„Î±: {len(st.session_state['sorter_irrelevant_files'])}." # ÎÎ•ÎŸ
        if st.session_state['sorter_duplicate_files']:
            final_message += f" ğŸ‘¯ Î”Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±: {len(st.session_state['sorter_duplicate_files'])}." # ÎÎ•ÎŸ
        
        status_callback(final_message, "success")
        logger.info(final_message)

        # ÎÎ•ÎŸ: Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Ï„Î·Ï‚ Ï„ÎµÎ»Î¹ÎºÎ®Ï‚ Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚ ÏƒÏ„Î¿ session state
        st.session_state['sorter_summary'] = {
            'last_run_timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_files_scanned': total_files if not specific_file_id else current_run_stats['total_files_scanned'], # If specific_file_id, total_files_scanned accumulates
            'total_successfully_sorted': current_run_stats['total_successfully_sorted'],
            'total_moved_to_manual_review': len(st.session_state['sorter_manual_review_files']),
            'total_moved_to_irrelevant': len(st.session_state['sorter_irrelevant_files']),
            'total_moved_to_duplicates': len(st.session_state['sorter_duplicate_files']),
            'category_counts': dict(current_run_stats['category_counts']),
            'brand_counts': dict(current_run_stats['brand_counts']),
            'type_counts': dict(current_run_stats['type_counts'])
        }