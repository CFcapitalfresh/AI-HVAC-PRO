"""
MODULE: UI CHAT (INTENT DRIVEN)
-------------------------------
Re-sorts manuals on the fly based on user prompt.
FIXED VERSION: Handles None types, adapts list to single-file AI Engine,
and includes Microphone/Upload buttons.
"""
import streamlit as st
import logging
from core.language_pack import get_text
from core.ai_engine import AIEngine
from services.chat_session import ChatSessionService
from core.drive_manager import DriveManager

# ŒëœÉœÜŒ±ŒªŒÆœÇ ŒµŒπœÉŒ±Œ≥œâŒ≥ŒÆ Œ≥ŒπŒ± œÑŒø ŒºŒπŒ∫œÅœåœÜœâŒΩŒø
try:
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    mic_recorder = None

# Œ°œçŒ∏ŒºŒπœÉŒ∑ Logger
logger = logging.getLogger(__name__)

def render(user):
    lang = st.session_state.get('lang', 'gr')
    session_srv = ChatSessionService()
    drive = DriveManager() # Local instance for file downloading if needed

    # --- DEVICE CONTEXT (SIDEBAR/TOP) ---
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 2, 3])
        brands = ["-"] + session_srv.get_brands()
        
        # Labels Œ±œÄœå œÑŒø Language Pack (ŒºŒµ fallback)
        lbl_brand = get_text('brand_label', lang) or "Brand"
        lbl_model = get_text('model_label', lang) or "Model"
        
        selected_brand = c1.selectbox(lbl_brand, brands, key="ctx_brand")
        selected_model = c2.text_input(lbl_model, key="ctx_model")
        
        # ŒëœÅœáŒπŒ∫ŒÆ ŒªŒØœÉœÑŒ± (œáœâœÅŒØœÇ ŒµœÅœéœÑŒ∑œÉŒ∑ Œ±Œ∫œåŒºŒ±)
        initial_manuals = []
        if selected_brand != "-":
            try:
                # Store potential manuals in session state for a more robust chat session flow
                st.session_state.chat_potential_manuals = session_srv.get_prioritized_manuals(selected_brand, selected_model, user_query="")
                if st.session_state.chat_potential_manuals:
                    msg = get_text('manuals_found', lang) or f"Found {len(st.session_state.chat_potential_manuals)}"
                    if "{count}" in msg:
                        c3.success(f"‚úÖ {msg.format(count=len(st.session_state.chat_potential_manuals))}")
                    else:
                        c3.success(f"‚úÖ {msg}")
                else:
                    msg = get_text('no_manuals', lang) or "No manuals"
                    c3.warning(msg)
            except Exception as e:
                logger.error(f"Error retrieving manuals: {e}")
                c3.error("Error loading manuals")
        else:
            msg = get_text('select_brand_for_search', lang) or "Select Brand"
            c3.info(msg)

    st.divider()
    
    # Init Chat History
    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- INPUT AREA (TABS) ---
    t_text = get_text('chat_tab_text', lang) or "‚å®Ô∏è Text"
    t_voice = get_text('chat_tab_voice', lang) or "üéôÔ∏è Voice"
    t_upload = get_text('chat_tab_upload', lang) or "üìé Manual Upload"
    
    tab_txt, tab_mic, tab_up = st.tabs([t_text, t_voice, t_upload])
    
    # User input and uploaded context initialization outside of tabs to allow access from all tabs
    user_prompt = None
    uploaded_context_file = None # Will hold the Streamlit file object (pdf or image)

    # 1. Text Input
    with tab_txt:
        ph = get_text('chat_input_placeholder', lang) or "Describe the issue..."
        prompt = st.chat_input(ph, key="chat_text_in")
        if prompt: user_prompt = prompt

    # 2. Voice Input
    with tab_mic:
        st.caption(get_text('chat_voice_under_dev', lang))
        if mic_recorder:
            st.write(get_text('voice_input_help', lang) or "Click to record:")
            audio = mic_recorder(start_prompt="üî¥ REC", stop_prompt="‚èπÔ∏è STOP", key='chat_mic_btn')
            if audio:
                st.info(get_text('voice_input_activated', lang) or "Audio received.")
                # Future implementation: Convert audio to text and set user_prompt
        else:
            st.warning("Mic recorder library missing.")

    # 3. File Upload (Rule 2: PDF/Image Support)
    with tab_up:
        lbl_up = get_text('upload_manual_label', lang) or "Upload File"
        st.caption(get_text('chat_upload_instructions', lang) or "Upload a PDF or image to send its content to the AI.")
        uploaded_context_file = st.file_uploader(lbl_up, type=["pdf", "png", "jpg", "jpeg"], key="chat_file_up")
        if uploaded_context_file: 
            st.success(f"üìé {uploaded_context_file.name}")
            manual_query = st.text_input(get_text('chat_manual_query_ph', lang) or "Tell the AI what to do with the manual...", key="chat_manual_query")
            if manual_query:
                # Set user_prompt from the manual query when submitted from this tab
                user_prompt = manual_query
                # To make this flow work, we need to ensure the user actually clicks something to send, 
                # or we process immediately when user_prompt is set.
                st.button(get_text('chat_send_manual_to_ai', lang), key="send_upload_btn", type="primary")

    # --- PROCESS INPUT ---
    if user_prompt:
        # A. Display user message and attached files
        with st.chat_message("user"):
            st.markdown(user_prompt)
            if uploaded_context_file:
                st.markdown(f"*üìé ŒïœÄŒπœÉœÖŒΩŒ¨œÜŒ∏Œ∑Œ∫Œµ: {uploaded_context_file.name}*")

        # B. AI Processing Logic (Refactored)
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""
            
            # 1. Get relevant manuals (based on context and query)
            # We already ran this logic above, but we pass the user's current query for prioritization
            final_manuals = session_srv.get_prioritized_manuals(selected_brand, selected_model, user_query)

            # 2. Prepare context for AI (Uploaded file OR Top library manual)
            # The AI can handle either an uploaded file or the text from a relevant library manual.
            # We prioritize uploaded files.
            manual_context_text = ""
            manual_context_name = ""
            
            # --- IF USER UPLOADED A FILE ---
            if uploaded_context_file:
                # Extract text from uploaded file for context (if possible) or pass bytes for Vision
                manual_context_name = uploaded_context_file.name
                if uploaded_context_file.type == 'application/pdf':
                    # Extract text from PDF bytes (safer than passing raw bytes directly to text-model)
                    try:
                        # Use get_manual_content_from_id logic but with uploaded file stream
                        manual_context_text = session_srv._extract_text_from_stream(uploaded_context_file.getvalue())
                    except Exception as e:
                        logger.warning(f"Failed to extract text from uploaded PDF: {e}")
                elif uploaded_context_file.type.startswith('image/'):
                    st.warning(get_text('chat_image_ocr_warning', lang))
                    # For images, we just rely on Vision capability and pass the prompt.
                    # No text extraction here for simplicity, AI will process image bytes directly.
            
            # --- IF NO UPLOAD, BUT RELEVANT MANUALS IN LIBRARY ---
            elif final_manuals:
                top_doc = final_manuals[0]
                manual_context_name = top_doc.get('name', 'N/A')
                lbl_studying = get_text('studying_sources', lang) or "Studying manuals..."
                with st.spinner(f"‚è≥ {lbl_studying} (Manual: {manual_context_name})"):
                    # Download and extract text from the top ranked manual from the library
                    manual_context_text = session_srv.get_manual_content_from_id(top_doc['file_id'])
            
            # 3. Call AI Engine with prepared content
            lbl_analyzing = get_text('analyzing', lang) or "Analyzing..."
            with st.spinner(lbl_analyzing):
                try:
                    # The call to get_chat_response now correctly passes text content.
                    # The actual file bytes (uploaded_context_file.getvalue()) are passed only for a Vision model.
                    # Let's clean up the call to align with a consistent API.
                    
                    # --- REVISED AI CALL FOR ROBUSTNESS ---
                    brain = AIEngine() # Ensure AIEngine instance exists
                    
                    # The smart_solve service function (in chat_session.py) should ideally handle all this logic.
                    # For now, let's pass a comprehensive list of content parts to the AI.
                    
                    # 1. Build list of content parts
                    content_parts_list = []
                    # Add uploaded file bytes if present (for Vision models)
                    if uploaded_context_file:
                        content_parts_list.append({
                            "mime_type": uploaded_context_file.type,
                            "data": uploaded_context_file.getvalue()
                        })

                    # Add relevant text context (either from uploaded file or library manual)
                    if manual_context_text:
                        content_parts_list.append({"text": f"Context Manual: {manual_context_name}\n\n{manual_context_text}"})
                    
                    # Add user query (last message)
                    content_parts_list.append({"text": f"User Query: {user_prompt}"})

                    # 2. Call AI Engine (using content parts list)
                    resp = brain.get_chat_response(
                        content_parts=content_parts_list,
                        lang=lang
                    )
                    
                    # 3. Display and save response
                    response_placeholder.markdown(resp)
                    st.session_state.messages.append({"role": "assistant", "content": resp})

                except Exception as e:
                    err_lbl = get_text('ai_engine_error', lang) or "AI Error: {error}"
                    st.error(err_lbl.format(error=str(e)))
                    logger.error(f"AI Error: {e}")