"""
MODULE: UI CHAT (INTENT DRIVEN)
-------------------------------
Re-sorts manuals on the fly based on user prompt.
FIXED VERSION: Handles None types, adapts list to single-file AI Engine,
and includes Microphone/Upload buttons.
"""
import streamlit as st
import logging
from core.language_pack import get_text
from core.ai_engine import AIEngine # Keep import for setup checks, but remove direct call later.
from services.chat_session import ChatSessionService # Import for logic delegation (Rule 3)
from core.drive_manager import DriveManager

# Î‘ÏƒÏ†Î±Î»Î®Ï‚ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® Î³Î¹Î± Ï„Î¿ Î¼Î¹ÎºÏÏŒÏ†Ï‰Î½Î¿
try:
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    mic_recorder = None

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Logger
logger = logging.getLogger(__name__)

def render(user):
    lang = st.session_state.get('lang', 'gr')
    session_srv = ChatSessionService()
    drive = DriveManager() # Note: DriveManager instance in UI module, consider moving to service layer.

    # --- DEVICE CONTEXT (SIDEBAR/TOP) ---
    with st.container(border=True):
        c1, c2, c3 = st.columns([2, 2, 3])
        # Note: get_brands() should ideally be fast or cached, otherwise this call can slow down UI.
        brands = ["-"] + session_srv.get_brands() 
        
        # Labels Î±Ï€ÏŒ Ï„Î¿ Language Pack (Î¼Îµ fallback)
        lbl_brand = get_text('brand_label', lang) or "Brand"
        lbl_model = get_text('model_label', lang) or "Model"
        
        selected_brand = c1.selectbox(lbl_brand, brands, key="ctx_brand")
        selected_model = c2.text_input(lbl_model, key="ctx_model")
        
        # Î‘ÏÏ‡Î¹ÎºÎ® Î»Î¯ÏƒÏ„Î± (Ï‡Ï‰ÏÎ¯Ï‚ ÎµÏÏÏ„Î·ÏƒÎ· Î±ÎºÏŒÎ¼Î±)
        initial_manuals = []
        if selected_brand != "-":
            try:
                # Retrieve all relevant manuals (prioritized list)
                initial_manuals = session_srv.get_prioritized_manuals(selected_brand, selected_model, user_query="")
                if initial_manuals:
                    msg = get_text('manuals_found', lang) or f"Found {len(initial_manuals)}"
                    if "{count}" in msg:
                        c3.success(f"âœ… {msg.format(count=len(initial_manuals))}")
                    else:
                        c3.success(f"âœ… {msg}")
                else:
                    msg = get_text('no_manuals', lang) or "No manuals"
                    c3.warning(msg)
            except Exception as e:
                logger.error(f"Error retrieving manuals: {e}")
                c3.error("Error loading manuals")
        else:
            msg = get_text('select_brand_for_search', lang) or "Select Brand"
            c3.info(msg)

    st.divider()
    
    # Init Chat History (Rule 6)
    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- INPUT AREA (TABS) ---
    t_text = get_text('tab_text', lang) or "âŒ¨ï¸ Text"
    t_voice = get_text('tab_voice', lang) or "ğŸ™ï¸ Voice"
    t_upload = get_text('tab_upload', lang) or "ğŸ“ Upload"
    
    tab_txt, tab_mic, tab_up = st.tabs([t_text, t_voice, t_upload])
    
    user_input = None
    uploaded_context = None

    # 1. Text Input
    with tab_txt:
        ph = get_text('chat_input_placeholder', lang) or "Describe the issue..."
        prompt = st.chat_input(ph, key="chat_text_in")
        if prompt: user_input = prompt

    # 2. Voice Input (Rule 1)
    with tab_mic:
        if mic_recorder:
            st.write(get_text('voice_input_help', lang) or "Click to record:")
            audio = mic_recorder(start_prompt="ğŸ”´ REC", stop_prompt="â¹ï¸ STOP", key='chat_mic_btn')
            if audio:
                st.info(get_text('voice_input_activated', lang) or "Audio received.")
                # Î•Î´Ï Î¼ÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ¬ Î¸Î± Î¼Ï€ÎµÎ¹ Ï„Î¿ Speech-to-Text
        else:
            st.warning("Mic recorder library missing.")

    # 3. File Upload (Rule 2)
    with tab_up:
        lbl_up = get_text('upload_manual_label', lang) or "Upload File"
        upl = st.file_uploader(lbl_up, type=["pdf", "png", "jpg", "jpeg"], key="chat_file_up")
        if upl: 
            uploaded_context = upl
            st.success(f"ğŸ“ {upl.name}")

    # --- PROCESS INPUT ---
    if user_input:
        display_msg = user_input
        # Remove direct file handling and AI call here, delegate to ChatSessionService
        if uploaded_context:
            proc_msg = get_text('processing_uploaded_file', lang) or "File: {name}"
            display_msg += f"\n\nğŸ“ *{proc_msg.format(name=uploaded_context.name)}*"
        
        st.session_state.messages.append({"role": "user", "content": display_msg})
        with st.chat_message("user"): st.markdown(display_msg)

        with st.chat_message("assistant"):
            lbl_analyzing = get_text('analyzing', lang) or "Analyzing..."
            with st.spinner(lbl_analyzing):
                try:
                    # Fix 1 & 2: Delegate all logic to ChatSessionService (Rule 3)
                    # The ChatSessionService will handle the file download, context combination, and AI call.
                    # Pass the uploaded context and a reference to the prioritized manuals for processing.
                    resp = session_srv.smart_solve(
                        user_query=user_input,
                        uploaded_pdfs=[uploaded_context] if uploaded_context and uploaded_context.type == 'application/pdf' else [],
                        uploaded_imgs=[uploaded_context] if uploaded_context and uploaded_context.type != 'application/pdf' else [],
                        # Pass initial_manuals (the prioritized list from step 1) to smart_solve for processing.
                        manuals_list=initial_manuals, 
                        history=st.session_state.messages,
                        lang=lang
                    )
                    st.markdown(resp)
                    st.session_state.messages.append({"role": "assistant", "content": resp})

                except Exception as e:
                    err_lbl = get_text('ai_engine_error', lang) or "AI Error: {error}"
                    st.error(err_lbl.format(error=str(e)))
                    logger.error(f"AI Error: {e}")