import streamlit as st
import os
import shutil
import re
import time
from datetime import datetime

try:
    from openai import OpenAI
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    st.error("âš ï¸ Î¤ÏÎ­Î¾Îµ: pip install openai streamlit-mic-recorder")
    st.stop()

# --- 1. Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ---
st.set_page_config(page_title="Mastro Nek v45 (Smart Context)", page_icon="ğŸ§ ", layout="wide")

def get_project_inventory():
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï„Î· Î»Î¯ÏƒÏ„Î± Î±ÏÏ‡ÎµÎ¯Ï‰Î½ ÎºÎ±Î¹ Ï„Î¿ Î¼Î­Î³ÎµÎ¸ÏŒÏ‚ Ï„Î¿Ï…Ï‚."""
    inventory = []
    ignore = {'.git', '__pycache__', 'venv', 'backups', '.streamlit', 'data', '.db'}
    for dirpath, dirnames, filenames in os.walk("."):
        dirnames[:] = [d for d in dirnames if d not in ignore]
        for f in filenames:
            if f.endswith(('.py', '.json', '.css', '.txt', '.md')):
                rel_path = os.path.relpath(os.path.join(dirpath, f), ".")
                size_kb = os.path.getsize(rel_path) / 1024
                inventory.append({"path": rel_path, "size": size_kb})
    return inventory

def read_selected_files(selected_paths):
    """Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Î¼ÏŒÎ½Î¿ Ï„Î± ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î±."""
    context = ""
    for path in selected_paths:
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                context += f"\n--- FILE: {path} ---\n{f.read()}\n"
        except: pass
    return context

def apply_changes(text):
    pattern = r"### FILE: (.+?)\n.*?```(?:python|json|css)?\n(.*?)```"
    matches = re.findall(pattern, text, re.DOTALL)
    log = []
    for filename, code in matches:
        filename = filename.strip().replace("\\", "/")
        full_path = os.path.abspath(filename)
        if os.path.exists(full_path):
            os.makedirs("backups", exist_ok=True)
            shutil.copy2(full_path, f"backups/{os.path.basename(filename)}_{datetime.now().strftime('%H%M%S')}.bak")
        try:
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            with open(full_path, 'w', encoding='utf-8') as f: f.write(code.strip())
            log.append(f"âœ… Î•ÎÎ—ÎœÎ•Î¡Î©Î˜Î—ÎšÎ•: {filename}")
        except Exception as e: log.append(f"âŒ Î£Î¦Î‘Î›ÎœÎ‘: {e}")
    return "\n".join(log)

# --- 2. ENGINE ---
def run_deepseek(prompt, api_key, context):
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "Î•Î¯ÏƒÎ±Î¹ Î¿ Mastro Nek. ÎœÎ¯Î»Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬. Î”ÏÏƒÎµ FULL ÎºÏÎ´Î¹ÎºÎ± Î¼Îµ ### FILE: filename.py"},
                {"role": "user", "content": f"CONTEXT:\n{context}\n\nREQUEST: {prompt}"}
            ],
            temperature=0.2
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ DeepSeek Error: {str(e)}"

# --- 3. UI ---
def main():
    st.title("ğŸ§  Mastro Nek v45 (Smart Context Control)")
    
    inventory = get_project_inventory()
    
    with st.sidebar:
        st.header("DeepSeek API")
        api_key = st.text_input("API Key", type="password")
        st.divider()
        
        # Î•Î Î™Î›ÎŸÎ“Î— Î‘Î¡Î§Î•Î™Î©Î (Multi-select)
        st.subheader("ğŸ“ Î•Ï€Î¹Î»Î¿Î³Î® Î‘ÏÏ‡ÎµÎ¯Ï‰Î½ Î³Î¹Î± Î‘Î½Î¬Î»Ï…ÏƒÎ·")
        st.write("Î•Ï€Î¯Î»ÎµÎ¾Îµ ÎœÎŸÎÎŸ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î±Ï†Î¿ÏÎ¬ Î· ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ¿Ï….")
        all_paths = [i['path'] for i in inventory]
        
        # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î·Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ Ï„Î¿Ï… architect.py ÎºÎ±Î¹ main.py
        defaults = [p for p in all_paths if "architect.py" in p or "main.py" in p]
        selected_files = st.multiselect("Files:", all_paths, default=defaults)
        
        st.divider()
        audio = mic_recorder(start_prompt="ğŸ¤ Rec", stop_prompt="â¹ Stop", key='mic_v45')
        if st.button("ğŸ—‘ï¸ Clear Chat"):
            st.session_state.messages = []
            st.rerun()

    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    user_input = st.chat_input("Î¤Î¹ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± Î±Î»Î»Î¬Î¾Î¿Ï…Î¼Îµ;")
    
    if (user_input or audio) and api_key:
        prompt = user_input if user_input else "Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ® ÎµÎ½Ï„Î¿Î»Î®..."
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        # Î”Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ ÎœÎŸÎÎŸ Ï„Î± ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î±
        context = read_selected_files(selected_files)
        
        with st.chat_message("assistant"):
            with st.spinner(f"Î‘Î½Î¬Î»Ï…ÏƒÎ· {len(selected_files)} Î±ÏÏ‡ÎµÎ¯Ï‰Î½..."):
                response = run_deepseek(prompt, api_key, context)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
                if "### FILE:" in response:
                    if st.button("ğŸ’¾ Apply Changes"):
                        st.success(apply_changes(response))
                        time.sleep(1)
                        st.rerun()

if __name__ == "__main__":
    main()