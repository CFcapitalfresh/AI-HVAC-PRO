"""
MODULE: UI CHAT (INTENT DRIVEN)
-------------------------------
Description: Streamlit UI module for the AI Chat Assistant.
Integrates text, voice, and file uploads with the core AI service layer,
providing context-aware responses based on selected manuals and user input.

Architectural Notes:
- Adheres to Modularity Rule (Rule 3) by delegating business logic to ChatSessionService.
- Implements Microphone (Rule 1) and PDF Upload (Rule 2) via UI tabs.
- Uses Streamlit State (Rule 6) for chat history and context.
- Uses get_text (Rule 5) for multilingual support.
"""

import streamlit as st
import logging
from typing import List, Dict, Any, Optional

from core.language_pack import get_text
from core.ai_engine import AIEngine # Used here for type hint/info only
from services.chat_session import ChatSessionService
# DriveManager not directly needed in UI if ChatSessionService handles uploads

# Import Speech-to-Text library with graceful error handling (Rule 1)
try:
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    mic_recorder = None

# Œ°œçŒ∏ŒºŒπœÉŒ∑ Logger Œ≥ŒπŒ± œÑŒø Module (Rule 4)
logger = logging.getLogger("Module_Chat_UI")

def render(user):
    lang = st.session_state.get('lang', 'gr')
    # Use existing instance if available, otherwise create a new one.
    # Rule 3: Modularity - Use service layer for business logic.
    session_srv = ChatSessionService()
    # Removed direct instantiation of DriveManager in UI

    st.header(get_text('menu_chat', lang))

    # --- DEVICE CONTEXT (SIDEBAR/TOP) ---
    # ŒöŒ±ŒΩœåŒΩŒ±œÇ 5: ŒßœÅŒÆœÉŒ∑ get_text Œ≥ŒπŒ± labels
    # ŒöŒ±ŒΩœåŒΩŒ±œÇ 6: ŒàŒªŒµŒ≥œáŒøœÇ initialization keys (ŒºŒ≠œÉœâ œÑœâŒΩ key arguments)
    with st.container(border=True):
        col1, col2, col3 = st.columns([2, 2, 3])
        
        # Get brands from the service layer, which uses the library cache
        # If library_cache not loaded, this will return empty list.
        try:
            brands = ["-"] + session_srv.get_brands()
        except Exception as e:
            logger.error(f"Error fetching brands for chat context: {e}", exc_info=True)
            brands = ["-"]
            col3.error(get_text('general_ui_error', lang).format(error="Failed to load brands"))


        # Labels Œ±œÄœå œÑŒø Language Pack
        lbl_brand = get_text('brand_label', lang)
        lbl_model = get_text('model_label', lang)

        # Store selected brand and model in session state for cross-session access
        selected_brand = col1.selectbox(lbl_brand, brands, key="ctx_brand")
        selected_model = col2.text_input(lbl_model, key="ctx_model")

        # 1. ŒíœÅŒµœÇ œÑŒ± manuals Œ≥ŒπŒ± œÑŒ∑ŒΩ œÑœÅŒ≠œáŒøœÖœÉŒ± ŒµœÄŒπŒªŒøŒ≥ŒÆ
        initial_manuals = []
        if selected_brand != "-":
            try:
                initial_manuals = session_srv.get_prioritized_manuals(selected_brand, selected_model, user_query="")
                if initial_manuals:
                    msg = get_text('manuals_found', lang)
                    col3.success(f"‚úÖ {msg.format(count=len(initial_manuals))}")
                else:
                    msg = get_text('no_manuals', lang)
                    col3.warning(msg)
            except Exception as e:
                logger.error(f"Error retrieving manuals in UI: {e}", exc_info=True) # Rule 4: Logging error
                col3.error(get_text('general_ui_error', lang).format(error=str(e)))
        else:
            msg = get_text('select_brand_for_search', lang)
            col3.info(msg)

    st.divider()

    # Init Chat History (Rule 6: Streamlit State)
    if "messages" not in st.session_state: st.session_state.messages = []
    
    # Display chat history (Rule 6)
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- INPUT AREA (TABS) ---
    # Rule 5: Translation of tab names
    t_text = get_text('tab_text', lang)
    t_voice = get_text('tab_voice', lang)
    t_upload = get_text('tab_upload', lang)
    
    tab_txt, tab_mic, tab_up = st.tabs([t_text, t_voice, t_upload])
    
    user_prompt = None
    uploaded_pdfs_context: List[Any] = [] # List to hold file-like objects for AI (Rule 2)
    uploaded_imgs_context: List[Any] = [] # List to hold file-like objects for AI (Rule 2)

    # 1. Text Input (Standard Chat Input)
    with tab_txt:
        ph = get_text('chat_input_placeholder', lang)
        prompt_from_text = st.chat_input(ph, key="chat_text_in")
        if prompt_from_text: user_prompt = prompt_from_text

    # 2. Voice Input (Rule 1)
    with tab_mic:
        if mic_recorder:
            st.write(get_text('voice_input_help', lang))
            audio_bytes = mic_recorder(start_prompt="üî¥ REC", stop_prompt="‚èπÔ∏è STOP", key='chat_mic_btn')
            if audio_bytes:
                st.info(get_text('audio_received_msg', lang))
                # Placeholder for actual Speech-to-Text integration (Rule 1)
                # In a real application, this would call a STT service.
                # For now, we simulate by updating user_prompt with a placeholder text.
                user_prompt = get_text('processing_voice_to_text', lang) # Signal to the ChatSessionService that voice was used
                st.session_state['last_audio_bytes'] = audio_bytes # Store for potential later STT processing in service layer if needed
                st.rerun() # Rerun to process the prompt immediately
        else:
            st.warning(get_text('stt_not_available', lang))

    # 3. File Upload (Rule 2)
    with tab_up:
        st.write(get_text('upload_files_instructions', lang)) # Rule 5
        pdfs = st.file_uploader(get_text('upload_pdfs_label', lang), type=["pdf"], accept_multiple_files=True, key="chat_pdf_uploader")
        images = st.file_uploader(get_text('upload_images_label', lang), type=["png", "jpg", "jpeg"], accept_multiple_files=True, key="chat_img_uploader")
        
        if pdfs:
            uploaded_pdfs_context.extend(pdfs)
        if images:
            uploaded_imgs_context.extend(images)

        # Display number of files ready to be sent
        total_files_ready = len(uploaded_pdfs_context) + len(uploaded_imgs_context)
        if total_files_ready > 0:
            st.success(get_text('files_attached_msg', lang).format(count=total_files_ready))


    # --- PROCESS INPUT (IF ANY) ---
    if user_prompt or uploaded_pdfs_context or uploaded_imgs_context:
        # Pre-process user prompt from voice if it's the placeholder (Rule 1)
        if user_prompt == get_text('processing_voice_to_text', lang) and 'last_audio_bytes' in st.session_state:
            # Here, we'd ideally call a STT service
            # For now, simulate STT result or just use a generic message
            user_prompt = f"{get_text('audio_received_msg', lang)} (STT: 'This is a voice command placeholder')"
            # Clear audio bytes from session state after use
            del st.session_state['last_audio_bytes']


        # A. Display user message
        display_msg_content = user_prompt if user_prompt else f"*{get_text('files_attached_msg', lang).format(count=total_files_ready)}*"
        st.session_state.messages.append({"role": "user", "content": display_msg_content})
        with st.chat_message("user"):
            st.markdown(display_msg_content)
            if uploaded_pdfs_context or uploaded_imgs_context:
                st.markdown(get_text('files_attached_msg', lang).format(count=total_files_ready))

        # B. Process with AI (delegated to ChatSessionService)
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""
            
            try:
                with st.spinner(get_text('analyzing', lang)): # Rule 5
                    # Fix 1 & 2: Delegate all logic to ChatSessionService (Rule 3, Rule 2)
                    full_response = session_srv.process_chat_input(
                        user_query=user_prompt,
                        selected_brand=selected_brand,
                        selected_model=selected_model,
                        uploaded_pdfs=uploaded_pdfs_context, # Correctly pass the lists
                        uploaded_images=uploaded_imgs_context, # Correctly pass the lists
                        history=st.session_state.messages[:-1],
                        lang=lang,
                        user_email=user['email'] # Pass user email for logging (Rule 4)
                    )

                # C. Display AI response
                response_placeholder.markdown(full_response)
                
                # D. Save to Session State (Rule 6)
                st.session_state.messages.append({"role": "assistant", "content": full_response})

            except Exception as e:
                error_msg = f"‚ö†Ô∏è **{get_text('ai_execution_error', lang)}:** {str(e)}" # Rule 5
                response_placeholder.error(error_msg)
                logger.error(f"Chat UI Error during AI processing: {e}", exc_info=True) # Rule 4
                st.session_state.messages.append({"role": "assistant", "content": error_msg})